{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgRGqQH6xghg",
        "outputId": "34954926-c9b7-4818-924d-90a165476e25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "401/401 [==============================] - 3s 3ms/step - loss: 0.9344 - accuracy: 0.5736 - val_loss: 0.7746 - val_accuracy: 0.6450\n",
            "Epoch 2/200\n",
            "401/401 [==============================] - 1s 2ms/step - loss: 0.8256 - accuracy: 0.6209 - val_loss: 0.7539 - val_accuracy: 0.6350\n",
            "Epoch 3/200\n",
            "401/401 [==============================] - 1s 2ms/step - loss: 0.8007 - accuracy: 0.6384 - val_loss: 0.7643 - val_accuracy: 0.6450\n",
            "Epoch 4/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.7874 - accuracy: 0.6509 - val_loss: 0.7186 - val_accuracy: 0.6850\n",
            "Epoch 5/200\n",
            "401/401 [==============================] - 1s 2ms/step - loss: 0.7861 - accuracy: 0.6559 - val_loss: 0.7723 - val_accuracy: 0.6450\n",
            "Epoch 6/200\n",
            "401/401 [==============================] - 1s 2ms/step - loss: 0.7625 - accuracy: 0.6608 - val_loss: 0.7309 - val_accuracy: 0.6700\n",
            "Epoch 7/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.7715 - accuracy: 0.6683 - val_loss: 0.7150 - val_accuracy: 0.6800\n",
            "Epoch 8/200\n",
            "401/401 [==============================] - 1s 2ms/step - loss: 0.7667 - accuracy: 0.6559 - val_loss: 0.7672 - val_accuracy: 0.6100\n",
            "Epoch 9/200\n",
            "401/401 [==============================] - 1s 2ms/step - loss: 0.7739 - accuracy: 0.6571 - val_loss: 0.7488 - val_accuracy: 0.6400\n",
            "Epoch 10/200\n",
            "401/401 [==============================] - 1s 2ms/step - loss: 0.7679 - accuracy: 0.6658 - val_loss: 0.7533 - val_accuracy: 0.6450\n",
            "Epoch 11/200\n",
            "401/401 [==============================] - 2s 4ms/step - loss: 0.7385 - accuracy: 0.6534 - val_loss: 0.7246 - val_accuracy: 0.6500\n",
            "Epoch 12/200\n",
            "401/401 [==============================] - 2s 4ms/step - loss: 0.7443 - accuracy: 0.6559 - val_loss: 0.7616 - val_accuracy: 0.6400\n",
            "Epoch 13/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.7521 - accuracy: 0.6484 - val_loss: 0.7220 - val_accuracy: 0.6600\n",
            "Epoch 14/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.7501 - accuracy: 0.6608 - val_loss: 0.6866 - val_accuracy: 0.6750\n",
            "Epoch 15/200\n",
            "401/401 [==============================] - 1s 2ms/step - loss: 0.7547 - accuracy: 0.6608 - val_loss: 0.7376 - val_accuracy: 0.6350\n",
            "Epoch 16/200\n",
            "401/401 [==============================] - 1s 2ms/step - loss: 0.7367 - accuracy: 0.6870 - val_loss: 0.7430 - val_accuracy: 0.6250\n",
            "Epoch 17/200\n",
            "401/401 [==============================] - 1s 2ms/step - loss: 0.7323 - accuracy: 0.6534 - val_loss: 0.7008 - val_accuracy: 0.6650\n",
            "Epoch 18/200\n",
            "401/401 [==============================] - 1s 2ms/step - loss: 0.7348 - accuracy: 0.6658 - val_loss: 0.6995 - val_accuracy: 0.6500\n",
            "Epoch 19/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.7319 - accuracy: 0.6608 - val_loss: 0.7638 - val_accuracy: 0.6250\n",
            "Epoch 20/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.7296 - accuracy: 0.6746 - val_loss: 0.6884 - val_accuracy: 0.6700\n",
            "Epoch 21/200\n",
            "401/401 [==============================] - 1s 2ms/step - loss: 0.7300 - accuracy: 0.6696 - val_loss: 0.6929 - val_accuracy: 0.6600\n",
            "Epoch 22/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.7301 - accuracy: 0.6783 - val_loss: 0.7216 - val_accuracy: 0.6450\n",
            "Epoch 23/200\n",
            "401/401 [==============================] - 2s 4ms/step - loss: 0.7324 - accuracy: 0.6983 - val_loss: 0.7071 - val_accuracy: 0.6500\n",
            "Epoch 24/200\n",
            "401/401 [==============================] - 2s 5ms/step - loss: 0.7181 - accuracy: 0.6746 - val_loss: 0.7082 - val_accuracy: 0.6450\n",
            "Epoch 25/200\n",
            "401/401 [==============================] - 1s 2ms/step - loss: 0.7202 - accuracy: 0.6833 - val_loss: 0.6967 - val_accuracy: 0.6450\n",
            "Epoch 26/200\n",
            "401/401 [==============================] - 1s 2ms/step - loss: 0.7185 - accuracy: 0.6758 - val_loss: 0.7139 - val_accuracy: 0.6300\n",
            "Epoch 27/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.7210 - accuracy: 0.6733 - val_loss: 0.7378 - val_accuracy: 0.6350\n",
            "Epoch 28/200\n",
            "401/401 [==============================] - 1s 2ms/step - loss: 0.7241 - accuracy: 0.6895 - val_loss: 0.7280 - val_accuracy: 0.6400\n",
            "Epoch 29/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.7133 - accuracy: 0.6633 - val_loss: 0.6863 - val_accuracy: 0.6750\n",
            "Epoch 30/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.7141 - accuracy: 0.6733 - val_loss: 0.7106 - val_accuracy: 0.6750\n",
            "Epoch 31/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.7063 - accuracy: 0.6870 - val_loss: 0.7375 - val_accuracy: 0.6450\n",
            "Epoch 32/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.7068 - accuracy: 0.6671 - val_loss: 0.7163 - val_accuracy: 0.6500\n",
            "Epoch 33/200\n",
            "401/401 [==============================] - 1s 2ms/step - loss: 0.7086 - accuracy: 0.6858 - val_loss: 0.6956 - val_accuracy: 0.6700\n",
            "Epoch 34/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.7141 - accuracy: 0.6746 - val_loss: 0.7296 - val_accuracy: 0.6250\n",
            "Epoch 35/200\n",
            "401/401 [==============================] - 2s 4ms/step - loss: 0.6914 - accuracy: 0.6908 - val_loss: 0.7083 - val_accuracy: 0.6700\n",
            "Epoch 36/200\n",
            "401/401 [==============================] - 2s 4ms/step - loss: 0.6929 - accuracy: 0.6945 - val_loss: 0.7071 - val_accuracy: 0.6850\n",
            "Epoch 37/200\n",
            "401/401 [==============================] - 1s 2ms/step - loss: 0.6910 - accuracy: 0.6796 - val_loss: 0.7042 - val_accuracy: 0.6750\n",
            "Epoch 38/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.6845 - accuracy: 0.6883 - val_loss: 0.7206 - val_accuracy: 0.6600\n",
            "Epoch 39/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.6838 - accuracy: 0.6933 - val_loss: 0.6780 - val_accuracy: 0.6750\n",
            "Epoch 40/200\n",
            "401/401 [==============================] - 1s 2ms/step - loss: 0.6814 - accuracy: 0.7020 - val_loss: 0.6898 - val_accuracy: 0.6700\n",
            "Epoch 41/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.6818 - accuracy: 0.6983 - val_loss: 0.7121 - val_accuracy: 0.6650\n",
            "Epoch 42/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.6901 - accuracy: 0.7020 - val_loss: 0.7054 - val_accuracy: 0.6350\n",
            "Epoch 43/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.6947 - accuracy: 0.6883 - val_loss: 0.7000 - val_accuracy: 0.6800\n",
            "Epoch 44/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.6844 - accuracy: 0.6758 - val_loss: 0.7080 - val_accuracy: 0.6650\n",
            "Epoch 45/200\n",
            "401/401 [==============================] - 1s 2ms/step - loss: 0.6707 - accuracy: 0.6958 - val_loss: 0.6959 - val_accuracy: 0.6800\n",
            "Epoch 46/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.6799 - accuracy: 0.6908 - val_loss: 0.7531 - val_accuracy: 0.6150\n",
            "Epoch 47/200\n",
            "401/401 [==============================] - 2s 4ms/step - loss: 0.6689 - accuracy: 0.7007 - val_loss: 0.7007 - val_accuracy: 0.6800\n",
            "Epoch 48/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.6681 - accuracy: 0.7020 - val_loss: 0.7035 - val_accuracy: 0.6600\n",
            "Epoch 49/200\n",
            "401/401 [==============================] - 1s 2ms/step - loss: 0.6650 - accuracy: 0.7007 - val_loss: 0.7047 - val_accuracy: 0.6600\n",
            "Epoch 50/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.6664 - accuracy: 0.6933 - val_loss: 0.7384 - val_accuracy: 0.6400\n",
            "Epoch 51/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.6655 - accuracy: 0.7132 - val_loss: 0.6990 - val_accuracy: 0.6450\n",
            "Epoch 52/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.6603 - accuracy: 0.7095 - val_loss: 0.7037 - val_accuracy: 0.6600\n",
            "Epoch 53/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.6667 - accuracy: 0.6970 - val_loss: 0.7251 - val_accuracy: 0.6600\n",
            "Epoch 54/200\n",
            "401/401 [==============================] - 1s 2ms/step - loss: 0.6596 - accuracy: 0.7132 - val_loss: 0.7224 - val_accuracy: 0.6250\n",
            "Epoch 55/200\n",
            "401/401 [==============================] - 1s 2ms/step - loss: 0.6644 - accuracy: 0.7045 - val_loss: 0.7058 - val_accuracy: 0.6650\n",
            "Epoch 56/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.6617 - accuracy: 0.7070 - val_loss: 0.6504 - val_accuracy: 0.7100\n",
            "Epoch 57/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.6482 - accuracy: 0.6995 - val_loss: 0.6710 - val_accuracy: 0.6850\n",
            "Epoch 58/200\n",
            "401/401 [==============================] - 1s 4ms/step - loss: 0.6408 - accuracy: 0.7232 - val_loss: 0.6543 - val_accuracy: 0.6800\n",
            "Epoch 59/200\n",
            "401/401 [==============================] - 2s 4ms/step - loss: 0.6481 - accuracy: 0.7219 - val_loss: 0.7021 - val_accuracy: 0.6800\n",
            "Epoch 60/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.6398 - accuracy: 0.7082 - val_loss: 0.7452 - val_accuracy: 0.6500\n",
            "Epoch 61/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.6590 - accuracy: 0.6970 - val_loss: 0.6804 - val_accuracy: 0.6850\n",
            "Epoch 62/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.6315 - accuracy: 0.7057 - val_loss: 0.7374 - val_accuracy: 0.6800\n",
            "Epoch 63/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.6230 - accuracy: 0.7269 - val_loss: 0.7006 - val_accuracy: 0.6650\n",
            "Epoch 64/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.6353 - accuracy: 0.7195 - val_loss: 0.7357 - val_accuracy: 0.6300\n",
            "Epoch 65/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.6409 - accuracy: 0.7195 - val_loss: 0.6751 - val_accuracy: 0.6850\n",
            "Epoch 66/200\n",
            "401/401 [==============================] - 1s 2ms/step - loss: 0.6522 - accuracy: 0.6958 - val_loss: 0.6999 - val_accuracy: 0.6650\n",
            "Epoch 67/200\n",
            "401/401 [==============================] - 1s 2ms/step - loss: 0.6236 - accuracy: 0.7207 - val_loss: 0.6837 - val_accuracy: 0.6700\n",
            "Epoch 68/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.6276 - accuracy: 0.7207 - val_loss: 0.6862 - val_accuracy: 0.6750\n",
            "Epoch 69/200\n",
            "401/401 [==============================] - 1s 2ms/step - loss: 0.6186 - accuracy: 0.7170 - val_loss: 0.7056 - val_accuracy: 0.6600\n",
            "Epoch 70/200\n",
            "401/401 [==============================] - 2s 4ms/step - loss: 0.6192 - accuracy: 0.7107 - val_loss: 0.7163 - val_accuracy: 0.6700\n",
            "Epoch 71/200\n",
            "401/401 [==============================] - 2s 4ms/step - loss: 0.6104 - accuracy: 0.7244 - val_loss: 0.6658 - val_accuracy: 0.7050\n",
            "Epoch 72/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.6238 - accuracy: 0.7232 - val_loss: 0.6977 - val_accuracy: 0.6650\n",
            "Epoch 73/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.6084 - accuracy: 0.7145 - val_loss: 0.7169 - val_accuracy: 0.6650\n",
            "Epoch 74/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.6424 - accuracy: 0.7082 - val_loss: 0.7133 - val_accuracy: 0.6550\n",
            "Epoch 75/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.6055 - accuracy: 0.7219 - val_loss: 0.6924 - val_accuracy: 0.6550\n",
            "Epoch 76/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.6189 - accuracy: 0.6983 - val_loss: 0.6813 - val_accuracy: 0.6800\n",
            "Epoch 77/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.6025 - accuracy: 0.7244 - val_loss: 0.7403 - val_accuracy: 0.6650\n",
            "Epoch 78/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.6154 - accuracy: 0.7282 - val_loss: 0.7225 - val_accuracy: 0.6650\n",
            "Epoch 79/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.5996 - accuracy: 0.7332 - val_loss: 0.7622 - val_accuracy: 0.5850\n",
            "Epoch 80/200\n",
            "401/401 [==============================] - 1s 2ms/step - loss: 0.6074 - accuracy: 0.7332 - val_loss: 0.6821 - val_accuracy: 0.6900\n",
            "Epoch 81/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.5932 - accuracy: 0.7170 - val_loss: 0.6764 - val_accuracy: 0.7150\n",
            "Epoch 82/200\n",
            "401/401 [==============================] - 2s 4ms/step - loss: 0.5643 - accuracy: 0.7556 - val_loss: 0.7035 - val_accuracy: 0.6850\n",
            "Epoch 83/200\n",
            "401/401 [==============================] - 1s 4ms/step - loss: 0.6087 - accuracy: 0.7307 - val_loss: 0.6925 - val_accuracy: 0.6450\n",
            "Epoch 84/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.5866 - accuracy: 0.7244 - val_loss: 0.7522 - val_accuracy: 0.6500\n",
            "Epoch 85/200\n",
            "401/401 [==============================] - 1s 2ms/step - loss: 0.5605 - accuracy: 0.7357 - val_loss: 0.7432 - val_accuracy: 0.6700\n",
            "Epoch 86/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.5777 - accuracy: 0.7344 - val_loss: 0.7579 - val_accuracy: 0.6700\n",
            "Epoch 87/200\n",
            "401/401 [==============================] - 1s 2ms/step - loss: 0.5618 - accuracy: 0.7406 - val_loss: 0.6810 - val_accuracy: 0.7050\n",
            "Epoch 88/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.5810 - accuracy: 0.7319 - val_loss: 0.6932 - val_accuracy: 0.6850\n",
            "Epoch 89/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.5816 - accuracy: 0.7307 - val_loss: 0.7125 - val_accuracy: 0.6700\n",
            "Epoch 90/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.5608 - accuracy: 0.7469 - val_loss: 0.7333 - val_accuracy: 0.6750\n",
            "Epoch 91/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.5765 - accuracy: 0.7207 - val_loss: 0.7648 - val_accuracy: 0.6600\n",
            "Epoch 92/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.5573 - accuracy: 0.7444 - val_loss: 0.6756 - val_accuracy: 0.6750\n",
            "Epoch 93/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.5440 - accuracy: 0.7606 - val_loss: 0.6618 - val_accuracy: 0.6800\n",
            "Epoch 94/200\n",
            "401/401 [==============================] - 2s 4ms/step - loss: 0.5438 - accuracy: 0.7431 - val_loss: 0.7689 - val_accuracy: 0.6600\n",
            "Epoch 95/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.5660 - accuracy: 0.7469 - val_loss: 0.7038 - val_accuracy: 0.6750\n",
            "Epoch 96/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.5529 - accuracy: 0.7406 - val_loss: 0.7292 - val_accuracy: 0.6650\n",
            "Epoch 97/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.5507 - accuracy: 0.7394 - val_loss: 0.7342 - val_accuracy: 0.6700\n",
            "Epoch 98/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.5389 - accuracy: 0.7519 - val_loss: 0.7826 - val_accuracy: 0.6700\n",
            "Epoch 99/200\n",
            "401/401 [==============================] - 1s 2ms/step - loss: 0.5352 - accuracy: 0.7431 - val_loss: 0.7219 - val_accuracy: 0.6750\n",
            "Epoch 100/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.5460 - accuracy: 0.7681 - val_loss: 0.6711 - val_accuracy: 0.6600\n",
            "Epoch 101/200\n",
            "401/401 [==============================] - 1s 2ms/step - loss: 0.5512 - accuracy: 0.7444 - val_loss: 0.7124 - val_accuracy: 0.6700\n",
            "Epoch 102/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.5380 - accuracy: 0.7469 - val_loss: 0.7779 - val_accuracy: 0.6450\n",
            "Epoch 103/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.5332 - accuracy: 0.7419 - val_loss: 0.7524 - val_accuracy: 0.6800\n",
            "Epoch 104/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.5450 - accuracy: 0.7556 - val_loss: 0.7258 - val_accuracy: 0.6600\n",
            "Epoch 105/200\n",
            "401/401 [==============================] - 2s 4ms/step - loss: 0.5440 - accuracy: 0.7456 - val_loss: 0.8427 - val_accuracy: 0.6950\n",
            "Epoch 106/200\n",
            "401/401 [==============================] - 2s 4ms/step - loss: 0.5116 - accuracy: 0.7606 - val_loss: 0.8003 - val_accuracy: 0.6800\n",
            "Epoch 107/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.5082 - accuracy: 0.7743 - val_loss: 0.8090 - val_accuracy: 0.6450\n",
            "Epoch 108/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.5119 - accuracy: 0.7768 - val_loss: 0.7660 - val_accuracy: 0.6500\n",
            "Epoch 109/200\n",
            "401/401 [==============================] - 1s 2ms/step - loss: 0.4999 - accuracy: 0.7681 - val_loss: 0.7543 - val_accuracy: 0.6550\n",
            "Epoch 110/200\n",
            "401/401 [==============================] - 1s 2ms/step - loss: 0.5345 - accuracy: 0.7594 - val_loss: 0.8143 - val_accuracy: 0.6450\n",
            "Epoch 111/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.5376 - accuracy: 0.7594 - val_loss: 0.7797 - val_accuracy: 0.6650\n",
            "Epoch 112/200\n",
            "401/401 [==============================] - 1s 2ms/step - loss: 0.5119 - accuracy: 0.7544 - val_loss: 0.7897 - val_accuracy: 0.6650\n",
            "Epoch 113/200\n",
            "401/401 [==============================] - 1s 2ms/step - loss: 0.5113 - accuracy: 0.7781 - val_loss: 0.7292 - val_accuracy: 0.6600\n",
            "Epoch 114/200\n",
            "401/401 [==============================] - 1s 2ms/step - loss: 0.4970 - accuracy: 0.7768 - val_loss: 0.7412 - val_accuracy: 0.6300\n",
            "Epoch 115/200\n",
            "401/401 [==============================] - 1s 2ms/step - loss: 0.5031 - accuracy: 0.7618 - val_loss: 0.9859 - val_accuracy: 0.6800\n",
            "Epoch 116/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.4967 - accuracy: 0.7731 - val_loss: 0.7507 - val_accuracy: 0.6400\n",
            "Epoch 117/200\n",
            "401/401 [==============================] - 2s 4ms/step - loss: 0.5380 - accuracy: 0.7556 - val_loss: 0.7878 - val_accuracy: 0.6550\n",
            "Epoch 118/200\n",
            "401/401 [==============================] - 2s 4ms/step - loss: 0.4945 - accuracy: 0.7681 - val_loss: 0.8374 - val_accuracy: 0.6200\n",
            "Epoch 119/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.4937 - accuracy: 0.7668 - val_loss: 0.9439 - val_accuracy: 0.6450\n",
            "Epoch 120/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.4845 - accuracy: 0.7805 - val_loss: 0.7804 - val_accuracy: 0.6900\n",
            "Epoch 121/200\n",
            "401/401 [==============================] - 1s 2ms/step - loss: 0.5021 - accuracy: 0.7444 - val_loss: 0.9894 - val_accuracy: 0.6350\n",
            "Epoch 122/200\n",
            "401/401 [==============================] - 1s 2ms/step - loss: 0.5128 - accuracy: 0.7793 - val_loss: 0.7876 - val_accuracy: 0.6650\n",
            "Epoch 123/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.4931 - accuracy: 0.7830 - val_loss: 0.7966 - val_accuracy: 0.6700\n",
            "Epoch 124/200\n",
            "401/401 [==============================] - 1s 2ms/step - loss: 0.4831 - accuracy: 0.7706 - val_loss: 0.8208 - val_accuracy: 0.6550\n",
            "Epoch 125/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.4922 - accuracy: 0.7781 - val_loss: 0.8213 - val_accuracy: 0.6950\n",
            "Epoch 126/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.4997 - accuracy: 0.7693 - val_loss: 0.8237 - val_accuracy: 0.6500\n",
            "Epoch 127/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.4845 - accuracy: 0.7693 - val_loss: 0.8482 - val_accuracy: 0.6400\n",
            "Epoch 128/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.4772 - accuracy: 0.7880 - val_loss: 0.8073 - val_accuracy: 0.7000\n",
            "Epoch 129/200\n",
            "401/401 [==============================] - 2s 5ms/step - loss: 0.4803 - accuracy: 0.7843 - val_loss: 0.8172 - val_accuracy: 0.6850\n",
            "Epoch 130/200\n",
            "401/401 [==============================] - 1s 4ms/step - loss: 0.4751 - accuracy: 0.7756 - val_loss: 0.7864 - val_accuracy: 0.6500\n",
            "Epoch 131/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.4894 - accuracy: 0.7731 - val_loss: 0.8282 - val_accuracy: 0.6750\n",
            "Epoch 132/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.4857 - accuracy: 0.7818 - val_loss: 0.7833 - val_accuracy: 0.6450\n",
            "Epoch 133/200\n",
            "401/401 [==============================] - 1s 2ms/step - loss: 0.4663 - accuracy: 0.7793 - val_loss: 0.7521 - val_accuracy: 0.6600\n",
            "Epoch 134/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.4642 - accuracy: 0.7706 - val_loss: 0.8389 - val_accuracy: 0.6750\n",
            "Epoch 135/200\n",
            "401/401 [==============================] - 1s 2ms/step - loss: 0.4955 - accuracy: 0.7656 - val_loss: 0.7954 - val_accuracy: 0.6600\n",
            "Epoch 136/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.4466 - accuracy: 0.7943 - val_loss: 0.8011 - val_accuracy: 0.6750\n",
            "Epoch 137/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.4737 - accuracy: 0.7805 - val_loss: 0.9171 - val_accuracy: 0.6300\n",
            "Epoch 138/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.4540 - accuracy: 0.7880 - val_loss: 0.7610 - val_accuracy: 0.6950\n",
            "Epoch 139/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.4611 - accuracy: 0.7955 - val_loss: 0.7957 - val_accuracy: 0.6450\n",
            "Epoch 140/200\n",
            "401/401 [==============================] - 2s 4ms/step - loss: 0.4584 - accuracy: 0.7993 - val_loss: 0.8030 - val_accuracy: 0.6250\n",
            "Epoch 141/200\n",
            "401/401 [==============================] - 2s 4ms/step - loss: 0.4478 - accuracy: 0.7930 - val_loss: 0.8756 - val_accuracy: 0.6500\n",
            "Epoch 142/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.4542 - accuracy: 0.7843 - val_loss: 0.8352 - val_accuracy: 0.6900\n",
            "Epoch 143/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.4362 - accuracy: 0.8042 - val_loss: 0.8547 - val_accuracy: 0.6600\n",
            "Epoch 144/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.4942 - accuracy: 0.7731 - val_loss: 0.8158 - val_accuracy: 0.6750\n",
            "Epoch 145/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.4491 - accuracy: 0.7855 - val_loss: 0.8150 - val_accuracy: 0.6850\n",
            "Epoch 146/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.4397 - accuracy: 0.8080 - val_loss: 0.8913 - val_accuracy: 0.6750\n",
            "Epoch 147/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.4565 - accuracy: 0.8030 - val_loss: 0.7852 - val_accuracy: 0.6700\n",
            "Epoch 148/200\n",
            "401/401 [==============================] - 1s 2ms/step - loss: 0.4560 - accuracy: 0.8042 - val_loss: 0.8461 - val_accuracy: 0.6450\n",
            "Epoch 149/200\n",
            "401/401 [==============================] - 1s 2ms/step - loss: 0.4246 - accuracy: 0.8092 - val_loss: 0.8793 - val_accuracy: 0.6700\n",
            "Epoch 150/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.4386 - accuracy: 0.7868 - val_loss: 0.9485 - val_accuracy: 0.6350\n",
            "Epoch 151/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.5289 - accuracy: 0.7731 - val_loss: 0.9570 - val_accuracy: 0.6600\n",
            "Epoch 152/200\n",
            "401/401 [==============================] - 2s 4ms/step - loss: 0.4438 - accuracy: 0.7968 - val_loss: 0.8615 - val_accuracy: 0.6700\n",
            "Epoch 153/200\n",
            "401/401 [==============================] - 1s 4ms/step - loss: 0.4129 - accuracy: 0.7980 - val_loss: 0.9497 - val_accuracy: 0.6700\n",
            "Epoch 154/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.4231 - accuracy: 0.8105 - val_loss: 0.8247 - val_accuracy: 0.6600\n",
            "Epoch 155/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.4483 - accuracy: 0.8180 - val_loss: 0.8824 - val_accuracy: 0.6800\n",
            "Epoch 156/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.4597 - accuracy: 0.7905 - val_loss: 0.8837 - val_accuracy: 0.6450\n",
            "Epoch 157/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.4701 - accuracy: 0.8017 - val_loss: 0.9872 - val_accuracy: 0.6600\n",
            "Epoch 158/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.4256 - accuracy: 0.8130 - val_loss: 1.0013 - val_accuracy: 0.6450\n",
            "Epoch 159/200\n",
            "401/401 [==============================] - 1s 2ms/step - loss: 0.4172 - accuracy: 0.8030 - val_loss: 0.9419 - val_accuracy: 0.6800\n",
            "Epoch 160/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.4419 - accuracy: 0.8229 - val_loss: 0.8598 - val_accuracy: 0.6900\n",
            "Epoch 161/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.4303 - accuracy: 0.8017 - val_loss: 0.8496 - val_accuracy: 0.6350\n",
            "Epoch 162/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.4027 - accuracy: 0.8067 - val_loss: 0.8677 - val_accuracy: 0.6750\n",
            "Epoch 163/200\n",
            "401/401 [==============================] - 2s 4ms/step - loss: 0.4068 - accuracy: 0.8142 - val_loss: 0.9314 - val_accuracy: 0.7000\n",
            "Epoch 164/200\n",
            "401/401 [==============================] - 2s 4ms/step - loss: 0.4362 - accuracy: 0.8005 - val_loss: 0.8287 - val_accuracy: 0.6700\n",
            "Epoch 165/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.4148 - accuracy: 0.8092 - val_loss: 0.8792 - val_accuracy: 0.6400\n",
            "Epoch 166/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.4199 - accuracy: 0.8180 - val_loss: 0.9573 - val_accuracy: 0.6350\n",
            "Epoch 167/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.4357 - accuracy: 0.8017 - val_loss: 1.0194 - val_accuracy: 0.6450\n",
            "Epoch 168/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.4378 - accuracy: 0.8142 - val_loss: 0.9813 - val_accuracy: 0.6350\n",
            "Epoch 169/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.4472 - accuracy: 0.8030 - val_loss: 0.8886 - val_accuracy: 0.6850\n",
            "Epoch 170/200\n",
            "401/401 [==============================] - 1s 2ms/step - loss: 0.4109 - accuracy: 0.8030 - val_loss: 1.0126 - val_accuracy: 0.6650\n",
            "Epoch 171/200\n",
            "401/401 [==============================] - 1s 2ms/step - loss: 0.4067 - accuracy: 0.8167 - val_loss: 0.9073 - val_accuracy: 0.6950\n",
            "Epoch 172/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.4181 - accuracy: 0.8080 - val_loss: 1.1015 - val_accuracy: 0.6400\n",
            "Epoch 173/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.4329 - accuracy: 0.8055 - val_loss: 0.9244 - val_accuracy: 0.6400\n",
            "Epoch 174/200\n",
            "401/401 [==============================] - 1s 2ms/step - loss: 0.4342 - accuracy: 0.8155 - val_loss: 0.9067 - val_accuracy: 0.6850\n",
            "Epoch 175/200\n",
            "401/401 [==============================] - 2s 4ms/step - loss: 0.4218 - accuracy: 0.8155 - val_loss: 0.9776 - val_accuracy: 0.6900\n",
            "Epoch 176/200\n",
            "401/401 [==============================] - 2s 4ms/step - loss: 0.4125 - accuracy: 0.8167 - val_loss: 0.9404 - val_accuracy: 0.6300\n",
            "Epoch 177/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.3925 - accuracy: 0.8279 - val_loss: 1.0055 - val_accuracy: 0.6950\n",
            "Epoch 178/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.4380 - accuracy: 0.8142 - val_loss: 0.9266 - val_accuracy: 0.6850\n",
            "Epoch 179/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.3902 - accuracy: 0.8192 - val_loss: 1.0796 - val_accuracy: 0.6700\n",
            "Epoch 180/200\n",
            "401/401 [==============================] - 1s 2ms/step - loss: 0.4091 - accuracy: 0.8342 - val_loss: 0.9009 - val_accuracy: 0.6750\n",
            "Epoch 181/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.3921 - accuracy: 0.8167 - val_loss: 0.9240 - val_accuracy: 0.6700\n",
            "Epoch 182/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.3700 - accuracy: 0.8454 - val_loss: 0.8485 - val_accuracy: 0.6500\n",
            "Epoch 183/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.4197 - accuracy: 0.8279 - val_loss: 0.9890 - val_accuracy: 0.6450\n",
            "Epoch 184/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.4396 - accuracy: 0.8005 - val_loss: 0.9677 - val_accuracy: 0.6900\n",
            "Epoch 185/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.4094 - accuracy: 0.8192 - val_loss: 0.9814 - val_accuracy: 0.6950\n",
            "Epoch 186/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.4037 - accuracy: 0.8130 - val_loss: 1.0000 - val_accuracy: 0.6500\n",
            "Epoch 187/200\n",
            "401/401 [==============================] - 2s 4ms/step - loss: 0.3785 - accuracy: 0.8254 - val_loss: 1.0773 - val_accuracy: 0.6600\n",
            "Epoch 188/200\n",
            "401/401 [==============================] - 2s 4ms/step - loss: 0.3719 - accuracy: 0.8342 - val_loss: 1.0686 - val_accuracy: 0.6800\n",
            "Epoch 189/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.3669 - accuracy: 0.8416 - val_loss: 0.9892 - val_accuracy: 0.6550\n",
            "Epoch 190/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.3933 - accuracy: 0.8180 - val_loss: 0.9389 - val_accuracy: 0.7000\n",
            "Epoch 191/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.4143 - accuracy: 0.8130 - val_loss: 1.2162 - val_accuracy: 0.6600\n",
            "Epoch 192/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.4098 - accuracy: 0.8229 - val_loss: 1.0623 - val_accuracy: 0.6450\n",
            "Epoch 193/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.3589 - accuracy: 0.8379 - val_loss: 1.0797 - val_accuracy: 0.6500\n",
            "Epoch 194/200\n",
            "401/401 [==============================] - 1s 2ms/step - loss: 0.3893 - accuracy: 0.8130 - val_loss: 1.0294 - val_accuracy: 0.6950\n",
            "Epoch 195/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.3787 - accuracy: 0.8217 - val_loss: 1.0019 - val_accuracy: 0.6900\n",
            "Epoch 196/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.3693 - accuracy: 0.8329 - val_loss: 1.0974 - val_accuracy: 0.6500\n",
            "Epoch 197/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.3624 - accuracy: 0.8392 - val_loss: 1.0508 - val_accuracy: 0.6550\n",
            "Epoch 198/200\n",
            "401/401 [==============================] - 2s 4ms/step - loss: 0.4111 - accuracy: 0.8242 - val_loss: 0.9990 - val_accuracy: 0.6950\n",
            "Epoch 199/200\n",
            "401/401 [==============================] - 2s 4ms/step - loss: 0.3863 - accuracy: 0.8204 - val_loss: 0.9438 - val_accuracy: 0.6450\n",
            "Epoch 200/200\n",
            "401/401 [==============================] - 1s 3ms/step - loss: 0.4188 - accuracy: 0.8204 - val_loss: 1.0645 - val_accuracy: 0.6800\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e4642ceb0a0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import InputLayer, BatchNormalization, Dropout, Flatten, Dense, Activation, MaxPooling2D, Conv2D\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load train and test CSV files\n",
        "train_data = pd.read_csv('TRAIN.csv')  # Replace 'train.csv' with your actual train file\n",
        "test_data = pd.read_csv('TEST.csv')    # Replace 'test.csv' with your actual test file\n",
        "\n",
        "# Extract features and labels from train data\n",
        "x_train = train_data.iloc[:, 1:11].values\n",
        "y_train = train_data.iloc[:, 11].values\n",
        "\n",
        "# Extract features and labels from test data\n",
        "x_test = test_data.iloc[:, 1:11].values\n",
        "y_test = test_data.iloc[:, 11].values\n",
        "\n",
        "# Encode the target variable\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(y_train)\n",
        "y_test = label_encoder.transform(y_test)\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_test = scaler.transform(x_test)\n",
        "\n",
        "# Define a Dense Neural Network model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(256, activation='gelu', input_shape=(10,)))\n",
        "\n",
        "model.add(Dense(128, activation='gelu'))\n",
        "\n",
        "model.add(Dense(64, activation='gelu'))\n",
        "model.add(Dropout(0.3))  # Adding dropout with a rate of 30%\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "\n",
        "\n",
        "# Compile the model with Adam optimizer and a specific learning rate\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(x_train, y_train, epochs=200, batch_size=2, validation_data=(x_test, y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adamax  # Import SGD optimizer\n",
        "\n",
        "# Load the 'esophagitis.csv' file\n",
        "data = pd.read_csv('esophagities.csv')  # Replace with your actual file name\n",
        "\n",
        "# Extract features and labels\n",
        "x = data.iloc[:, 1:22].values\n",
        "y = data.iloc[:, 22].values\n",
        "\n",
        "# Encode the target variable\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split the data into train and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_test = scaler.transform(x_test)\n",
        "\n",
        "# Define the model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='gelu', input_shape=(21,)))\n",
        "model.add(Dense(256, activation='gelu'))\n",
        "model.add(Dense(128, activation='gelu'))\n",
        "model.add(Dense(64, activation='gelu'))\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(optimizer=Adamax(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(x_train, y_train, epochs=500, batch_size=2, validation_data=(x_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkNtDbeuXICQ",
        "outputId": "13e06a01-5e88-4c6f-a9ac-bb884e08897d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "350/350 [==============================] - 4s 4ms/step - loss: 0.8876 - accuracy: 0.5729 - val_loss: 0.8261 - val_accuracy: 0.6133\n",
            "Epoch 2/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.7860 - accuracy: 0.6414 - val_loss: 0.8001 - val_accuracy: 0.6400\n",
            "Epoch 3/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.7745 - accuracy: 0.6557 - val_loss: 0.7815 - val_accuracy: 0.6233\n",
            "Epoch 4/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.7520 - accuracy: 0.6700 - val_loss: 0.7710 - val_accuracy: 0.6400\n",
            "Epoch 5/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.7510 - accuracy: 0.6543 - val_loss: 0.7677 - val_accuracy: 0.6467\n",
            "Epoch 6/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.7368 - accuracy: 0.6714 - val_loss: 0.7869 - val_accuracy: 0.6133\n",
            "Epoch 7/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.7382 - accuracy: 0.6729 - val_loss: 0.7812 - val_accuracy: 0.6267\n",
            "Epoch 8/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.7299 - accuracy: 0.6729 - val_loss: 0.7741 - val_accuracy: 0.6367\n",
            "Epoch 9/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.7214 - accuracy: 0.6743 - val_loss: 0.8036 - val_accuracy: 0.6033\n",
            "Epoch 10/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.7158 - accuracy: 0.6886 - val_loss: 0.7865 - val_accuracy: 0.6367\n",
            "Epoch 11/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.7182 - accuracy: 0.6786 - val_loss: 0.7922 - val_accuracy: 0.6133\n",
            "Epoch 12/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.7085 - accuracy: 0.6729 - val_loss: 0.7840 - val_accuracy: 0.6133\n",
            "Epoch 13/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.7101 - accuracy: 0.6786 - val_loss: 0.7684 - val_accuracy: 0.6800\n",
            "Epoch 14/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.7068 - accuracy: 0.6743 - val_loss: 0.7903 - val_accuracy: 0.6433\n",
            "Epoch 15/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.7012 - accuracy: 0.6829 - val_loss: 0.7930 - val_accuracy: 0.6300\n",
            "Epoch 16/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.6987 - accuracy: 0.6886 - val_loss: 0.7865 - val_accuracy: 0.6733\n",
            "Epoch 17/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.6982 - accuracy: 0.6757 - val_loss: 0.8103 - val_accuracy: 0.6467\n",
            "Epoch 18/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.6998 - accuracy: 0.6900 - val_loss: 0.8043 - val_accuracy: 0.6300\n",
            "Epoch 19/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.6879 - accuracy: 0.6857 - val_loss: 0.7881 - val_accuracy: 0.6467\n",
            "Epoch 20/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.6980 - accuracy: 0.6814 - val_loss: 0.8113 - val_accuracy: 0.6333\n",
            "Epoch 21/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.6888 - accuracy: 0.6843 - val_loss: 0.8100 - val_accuracy: 0.6600\n",
            "Epoch 22/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.6899 - accuracy: 0.6900 - val_loss: 0.8221 - val_accuracy: 0.5967\n",
            "Epoch 23/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.6807 - accuracy: 0.6843 - val_loss: 0.8100 - val_accuracy: 0.6133\n",
            "Epoch 24/500\n",
            "350/350 [==============================] - 2s 4ms/step - loss: 0.6842 - accuracy: 0.6729 - val_loss: 0.8028 - val_accuracy: 0.6767\n",
            "Epoch 25/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.6823 - accuracy: 0.6929 - val_loss: 0.8040 - val_accuracy: 0.6200\n",
            "Epoch 26/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.6754 - accuracy: 0.6886 - val_loss: 0.8170 - val_accuracy: 0.6200\n",
            "Epoch 27/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.6873 - accuracy: 0.6786 - val_loss: 0.7859 - val_accuracy: 0.6333\n",
            "Epoch 28/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.6697 - accuracy: 0.6971 - val_loss: 0.8121 - val_accuracy: 0.6600\n",
            "Epoch 29/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.6699 - accuracy: 0.6957 - val_loss: 0.8403 - val_accuracy: 0.6167\n",
            "Epoch 30/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.6600 - accuracy: 0.7000 - val_loss: 0.8022 - val_accuracy: 0.6200\n",
            "Epoch 31/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.6686 - accuracy: 0.6914 - val_loss: 0.8321 - val_accuracy: 0.6567\n",
            "Epoch 32/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.6665 - accuracy: 0.6943 - val_loss: 0.8199 - val_accuracy: 0.6200\n",
            "Epoch 33/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.6609 - accuracy: 0.7057 - val_loss: 0.8143 - val_accuracy: 0.6400\n",
            "Epoch 34/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.6570 - accuracy: 0.7071 - val_loss: 0.8254 - val_accuracy: 0.6433\n",
            "Epoch 35/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.6542 - accuracy: 0.6929 - val_loss: 0.7895 - val_accuracy: 0.6333\n",
            "Epoch 36/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.6503 - accuracy: 0.6971 - val_loss: 0.8328 - val_accuracy: 0.6200\n",
            "Epoch 37/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.6385 - accuracy: 0.7057 - val_loss: 0.8870 - val_accuracy: 0.6567\n",
            "Epoch 38/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.6583 - accuracy: 0.6986 - val_loss: 0.8062 - val_accuracy: 0.6567\n",
            "Epoch 39/500\n",
            "350/350 [==============================] - 2s 4ms/step - loss: 0.6441 - accuracy: 0.6986 - val_loss: 0.8249 - val_accuracy: 0.6233\n",
            "Epoch 40/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.6370 - accuracy: 0.7157 - val_loss: 0.8023 - val_accuracy: 0.6600\n",
            "Epoch 41/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.6356 - accuracy: 0.7157 - val_loss: 0.8523 - val_accuracy: 0.6933\n",
            "Epoch 42/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.6363 - accuracy: 0.7043 - val_loss: 0.8327 - val_accuracy: 0.6567\n",
            "Epoch 43/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.6232 - accuracy: 0.7157 - val_loss: 0.8205 - val_accuracy: 0.6667\n",
            "Epoch 44/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.6355 - accuracy: 0.7171 - val_loss: 0.8012 - val_accuracy: 0.6933\n",
            "Epoch 45/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.6192 - accuracy: 0.7157 - val_loss: 0.8361 - val_accuracy: 0.6300\n",
            "Epoch 46/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.6180 - accuracy: 0.7086 - val_loss: 0.8822 - val_accuracy: 0.6267\n",
            "Epoch 47/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.6242 - accuracy: 0.7129 - val_loss: 0.8377 - val_accuracy: 0.6533\n",
            "Epoch 48/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.6176 - accuracy: 0.7071 - val_loss: 0.8710 - val_accuracy: 0.6467\n",
            "Epoch 49/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.6028 - accuracy: 0.7214 - val_loss: 0.9296 - val_accuracy: 0.5933\n",
            "Epoch 50/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.6134 - accuracy: 0.7100 - val_loss: 0.8585 - val_accuracy: 0.6467\n",
            "Epoch 51/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.6134 - accuracy: 0.7171 - val_loss: 0.8743 - val_accuracy: 0.6433\n",
            "Epoch 52/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.6006 - accuracy: 0.7243 - val_loss: 0.8812 - val_accuracy: 0.6133\n",
            "Epoch 53/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.6066 - accuracy: 0.7271 - val_loss: 0.9079 - val_accuracy: 0.6267\n",
            "Epoch 54/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.6066 - accuracy: 0.7071 - val_loss: 0.8257 - val_accuracy: 0.6800\n",
            "Epoch 55/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.6044 - accuracy: 0.7257 - val_loss: 0.9120 - val_accuracy: 0.6100\n",
            "Epoch 56/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.5949 - accuracy: 0.7271 - val_loss: 0.8826 - val_accuracy: 0.6433\n",
            "Epoch 57/500\n",
            "350/350 [==============================] - 2s 4ms/step - loss: 0.5950 - accuracy: 0.7200 - val_loss: 0.9256 - val_accuracy: 0.6400\n",
            "Epoch 58/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.5877 - accuracy: 0.7243 - val_loss: 0.9377 - val_accuracy: 0.6400\n",
            "Epoch 59/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.5905 - accuracy: 0.7343 - val_loss: 0.9049 - val_accuracy: 0.6267\n",
            "Epoch 60/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.5851 - accuracy: 0.7186 - val_loss: 0.9000 - val_accuracy: 0.6767\n",
            "Epoch 61/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.5839 - accuracy: 0.7271 - val_loss: 0.8912 - val_accuracy: 0.6367\n",
            "Epoch 62/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.5830 - accuracy: 0.7371 - val_loss: 0.9268 - val_accuracy: 0.6233\n",
            "Epoch 63/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.5775 - accuracy: 0.7357 - val_loss: 0.8751 - val_accuracy: 0.6233\n",
            "Epoch 64/500\n",
            "350/350 [==============================] - 3s 10ms/step - loss: 0.5745 - accuracy: 0.7457 - val_loss: 0.9224 - val_accuracy: 0.6433\n",
            "Epoch 65/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.5806 - accuracy: 0.7343 - val_loss: 0.8847 - val_accuracy: 0.6367\n",
            "Epoch 66/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.5742 - accuracy: 0.7314 - val_loss: 0.9147 - val_accuracy: 0.6533\n",
            "Epoch 67/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.5665 - accuracy: 0.7429 - val_loss: 0.9233 - val_accuracy: 0.6300\n",
            "Epoch 68/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.5680 - accuracy: 0.7314 - val_loss: 0.8990 - val_accuracy: 0.6600\n",
            "Epoch 69/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.5719 - accuracy: 0.7329 - val_loss: 0.9057 - val_accuracy: 0.6400\n",
            "Epoch 70/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.5613 - accuracy: 0.7443 - val_loss: 0.9203 - val_accuracy: 0.6367\n",
            "Epoch 71/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.5699 - accuracy: 0.7286 - val_loss: 0.8938 - val_accuracy: 0.6533\n",
            "Epoch 72/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.5665 - accuracy: 0.7300 - val_loss: 0.9146 - val_accuracy: 0.6633\n",
            "Epoch 73/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.5595 - accuracy: 0.7457 - val_loss: 0.9660 - val_accuracy: 0.6300\n",
            "Epoch 74/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.5597 - accuracy: 0.7314 - val_loss: 0.9499 - val_accuracy: 0.6367\n",
            "Epoch 75/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.5596 - accuracy: 0.7514 - val_loss: 0.9821 - val_accuracy: 0.6267\n",
            "Epoch 76/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.5454 - accuracy: 0.7414 - val_loss: 0.9758 - val_accuracy: 0.6500\n",
            "Epoch 77/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.5503 - accuracy: 0.7500 - val_loss: 0.9455 - val_accuracy: 0.6267\n",
            "Epoch 78/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.5482 - accuracy: 0.7500 - val_loss: 0.9569 - val_accuracy: 0.6567\n",
            "Epoch 79/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.5473 - accuracy: 0.7457 - val_loss: 0.9319 - val_accuracy: 0.6600\n",
            "Epoch 80/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.5374 - accuracy: 0.7414 - val_loss: 0.9692 - val_accuracy: 0.6467\n",
            "Epoch 81/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.5374 - accuracy: 0.7529 - val_loss: 0.9831 - val_accuracy: 0.6300\n",
            "Epoch 82/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.5448 - accuracy: 0.7529 - val_loss: 0.9784 - val_accuracy: 0.6367\n",
            "Epoch 83/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.5434 - accuracy: 0.7471 - val_loss: 1.0048 - val_accuracy: 0.6567\n",
            "Epoch 84/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.5340 - accuracy: 0.7586 - val_loss: 0.9467 - val_accuracy: 0.6667\n",
            "Epoch 85/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.5359 - accuracy: 0.7471 - val_loss: 0.9484 - val_accuracy: 0.6400\n",
            "Epoch 86/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.5325 - accuracy: 0.7629 - val_loss: 0.9986 - val_accuracy: 0.6567\n",
            "Epoch 87/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.5295 - accuracy: 0.7471 - val_loss: 1.0330 - val_accuracy: 0.6233\n",
            "Epoch 88/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.5332 - accuracy: 0.7543 - val_loss: 0.9915 - val_accuracy: 0.6467\n",
            "Epoch 89/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.5154 - accuracy: 0.7614 - val_loss: 1.0079 - val_accuracy: 0.6467\n",
            "Epoch 90/500\n",
            "350/350 [==============================] - 2s 4ms/step - loss: 0.5243 - accuracy: 0.7657 - val_loss: 1.0158 - val_accuracy: 0.6533\n",
            "Epoch 91/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.5204 - accuracy: 0.7629 - val_loss: 0.9644 - val_accuracy: 0.6533\n",
            "Epoch 92/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.5106 - accuracy: 0.7686 - val_loss: 1.0340 - val_accuracy: 0.6367\n",
            "Epoch 93/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.5174 - accuracy: 0.7686 - val_loss: 1.0502 - val_accuracy: 0.6433\n",
            "Epoch 94/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.5162 - accuracy: 0.7614 - val_loss: 1.0191 - val_accuracy: 0.6567\n",
            "Epoch 95/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.5130 - accuracy: 0.7729 - val_loss: 1.0429 - val_accuracy: 0.6367\n",
            "Epoch 96/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.5110 - accuracy: 0.7743 - val_loss: 0.9827 - val_accuracy: 0.6467\n",
            "Epoch 97/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.5006 - accuracy: 0.7800 - val_loss: 1.1399 - val_accuracy: 0.6200\n",
            "Epoch 98/500\n",
            "350/350 [==============================] - 2s 4ms/step - loss: 0.5047 - accuracy: 0.7700 - val_loss: 1.0589 - val_accuracy: 0.6500\n",
            "Epoch 99/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.4956 - accuracy: 0.7757 - val_loss: 1.0252 - val_accuracy: 0.6400\n",
            "Epoch 100/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.4959 - accuracy: 0.7757 - val_loss: 1.0900 - val_accuracy: 0.6500\n",
            "Epoch 101/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.4957 - accuracy: 0.7657 - val_loss: 1.0531 - val_accuracy: 0.6667\n",
            "Epoch 102/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.5046 - accuracy: 0.7700 - val_loss: 1.1100 - val_accuracy: 0.6500\n",
            "Epoch 103/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.4962 - accuracy: 0.7600 - val_loss: 1.0854 - val_accuracy: 0.6500\n",
            "Epoch 104/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.4827 - accuracy: 0.7657 - val_loss: 1.0766 - val_accuracy: 0.6433\n",
            "Epoch 105/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.4883 - accuracy: 0.7757 - val_loss: 1.1142 - val_accuracy: 0.6433\n",
            "Epoch 106/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.4762 - accuracy: 0.7857 - val_loss: 1.0954 - val_accuracy: 0.6467\n",
            "Epoch 107/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.4885 - accuracy: 0.7629 - val_loss: 1.1023 - val_accuracy: 0.6533\n",
            "Epoch 108/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.4809 - accuracy: 0.7800 - val_loss: 1.1879 - val_accuracy: 0.6533\n",
            "Epoch 109/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.4784 - accuracy: 0.7814 - val_loss: 1.1921 - val_accuracy: 0.6433\n",
            "Epoch 110/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.4692 - accuracy: 0.7729 - val_loss: 1.1427 - val_accuracy: 0.6867\n",
            "Epoch 111/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.4746 - accuracy: 0.7914 - val_loss: 1.1735 - val_accuracy: 0.6500\n",
            "Epoch 112/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.4706 - accuracy: 0.7886 - val_loss: 1.1548 - val_accuracy: 0.6533\n",
            "Epoch 113/500\n",
            "350/350 [==============================] - 2s 4ms/step - loss: 0.4669 - accuracy: 0.7886 - val_loss: 1.1394 - val_accuracy: 0.6700\n",
            "Epoch 114/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.4663 - accuracy: 0.7929 - val_loss: 1.1873 - val_accuracy: 0.6767\n",
            "Epoch 115/500\n",
            "350/350 [==============================] - 2s 4ms/step - loss: 0.4722 - accuracy: 0.7829 - val_loss: 1.1565 - val_accuracy: 0.6500\n",
            "Epoch 116/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.4644 - accuracy: 0.8014 - val_loss: 1.1561 - val_accuracy: 0.6667\n",
            "Epoch 117/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.4590 - accuracy: 0.7886 - val_loss: 1.1581 - val_accuracy: 0.6733\n",
            "Epoch 118/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.4649 - accuracy: 0.7800 - val_loss: 1.1586 - val_accuracy: 0.6633\n",
            "Epoch 119/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.4527 - accuracy: 0.7900 - val_loss: 1.2232 - val_accuracy: 0.6467\n",
            "Epoch 120/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.4610 - accuracy: 0.7843 - val_loss: 1.1915 - val_accuracy: 0.6333\n",
            "Epoch 121/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.4562 - accuracy: 0.8000 - val_loss: 1.1462 - val_accuracy: 0.6633\n",
            "Epoch 122/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.4510 - accuracy: 0.7814 - val_loss: 1.2545 - val_accuracy: 0.6600\n",
            "Epoch 123/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.4546 - accuracy: 0.8043 - val_loss: 1.1602 - val_accuracy: 0.6667\n",
            "Epoch 124/500\n",
            "350/350 [==============================] - 2s 7ms/step - loss: 0.4546 - accuracy: 0.7900 - val_loss: 1.1915 - val_accuracy: 0.6633\n",
            "Epoch 125/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.4418 - accuracy: 0.7857 - val_loss: 1.2165 - val_accuracy: 0.6600\n",
            "Epoch 126/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.4407 - accuracy: 0.8100 - val_loss: 1.2529 - val_accuracy: 0.6633\n",
            "Epoch 127/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.4460 - accuracy: 0.7914 - val_loss: 1.2697 - val_accuracy: 0.6467\n",
            "Epoch 128/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.4471 - accuracy: 0.7986 - val_loss: 1.2299 - val_accuracy: 0.6767\n",
            "Epoch 129/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.4404 - accuracy: 0.7957 - val_loss: 1.2087 - val_accuracy: 0.6367\n",
            "Epoch 130/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.4338 - accuracy: 0.8100 - val_loss: 1.1666 - val_accuracy: 0.6700\n",
            "Epoch 131/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.4367 - accuracy: 0.8043 - val_loss: 1.2285 - val_accuracy: 0.6433\n",
            "Epoch 132/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.4223 - accuracy: 0.8000 - val_loss: 1.1979 - val_accuracy: 0.6567\n",
            "Epoch 133/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.4306 - accuracy: 0.7971 - val_loss: 1.2485 - val_accuracy: 0.6800\n",
            "Epoch 134/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.4289 - accuracy: 0.8114 - val_loss: 1.2766 - val_accuracy: 0.6367\n",
            "Epoch 135/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.4278 - accuracy: 0.8114 - val_loss: 1.2918 - val_accuracy: 0.6633\n",
            "Epoch 136/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.4311 - accuracy: 0.8100 - val_loss: 1.2108 - val_accuracy: 0.6633\n",
            "Epoch 137/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.4193 - accuracy: 0.8143 - val_loss: 1.2805 - val_accuracy: 0.6600\n",
            "Epoch 138/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.4294 - accuracy: 0.8100 - val_loss: 1.3015 - val_accuracy: 0.6600\n",
            "Epoch 139/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.4305 - accuracy: 0.8186 - val_loss: 1.3221 - val_accuracy: 0.6667\n",
            "Epoch 140/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.4229 - accuracy: 0.8214 - val_loss: 1.2992 - val_accuracy: 0.6600\n",
            "Epoch 141/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.4133 - accuracy: 0.8043 - val_loss: 1.2810 - val_accuracy: 0.6600\n",
            "Epoch 142/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.4163 - accuracy: 0.8214 - val_loss: 1.3144 - val_accuracy: 0.6567\n",
            "Epoch 143/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.4068 - accuracy: 0.8214 - val_loss: 1.4112 - val_accuracy: 0.6667\n",
            "Epoch 144/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.4201 - accuracy: 0.8057 - val_loss: 1.3229 - val_accuracy: 0.6533\n",
            "Epoch 145/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.4091 - accuracy: 0.8229 - val_loss: 1.3779 - val_accuracy: 0.6633\n",
            "Epoch 146/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.4181 - accuracy: 0.7986 - val_loss: 1.3187 - val_accuracy: 0.6533\n",
            "Epoch 147/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3953 - accuracy: 0.8243 - val_loss: 1.3580 - val_accuracy: 0.6433\n",
            "Epoch 148/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.4043 - accuracy: 0.8143 - val_loss: 1.3302 - val_accuracy: 0.6567\n",
            "Epoch 149/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.3976 - accuracy: 0.8200 - val_loss: 1.3842 - val_accuracy: 0.6733\n",
            "Epoch 150/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.4069 - accuracy: 0.8314 - val_loss: 1.3490 - val_accuracy: 0.6600\n",
            "Epoch 151/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3926 - accuracy: 0.8329 - val_loss: 1.4064 - val_accuracy: 0.6400\n",
            "Epoch 152/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3934 - accuracy: 0.8229 - val_loss: 1.3429 - val_accuracy: 0.6733\n",
            "Epoch 153/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3916 - accuracy: 0.8357 - val_loss: 1.3742 - val_accuracy: 0.6400\n",
            "Epoch 154/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3893 - accuracy: 0.8329 - val_loss: 1.3739 - val_accuracy: 0.6633\n",
            "Epoch 155/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3815 - accuracy: 0.8271 - val_loss: 1.4190 - val_accuracy: 0.6700\n",
            "Epoch 156/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3931 - accuracy: 0.8314 - val_loss: 1.3979 - val_accuracy: 0.6667\n",
            "Epoch 157/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.3810 - accuracy: 0.8271 - val_loss: 1.4162 - val_accuracy: 0.6700\n",
            "Epoch 158/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.3893 - accuracy: 0.8357 - val_loss: 1.4649 - val_accuracy: 0.6500\n",
            "Epoch 159/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3834 - accuracy: 0.8257 - val_loss: 1.4116 - val_accuracy: 0.6833\n",
            "Epoch 160/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3737 - accuracy: 0.8229 - val_loss: 1.4744 - val_accuracy: 0.6533\n",
            "Epoch 161/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3852 - accuracy: 0.8300 - val_loss: 1.4570 - val_accuracy: 0.6633\n",
            "Epoch 162/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3724 - accuracy: 0.8500 - val_loss: 1.5633 - val_accuracy: 0.6400\n",
            "Epoch 163/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3745 - accuracy: 0.8271 - val_loss: 1.5067 - val_accuracy: 0.6367\n",
            "Epoch 164/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3668 - accuracy: 0.8400 - val_loss: 1.4868 - val_accuracy: 0.6633\n",
            "Epoch 165/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.3683 - accuracy: 0.8343 - val_loss: 1.5841 - val_accuracy: 0.6467\n",
            "Epoch 166/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.3734 - accuracy: 0.8357 - val_loss: 1.4331 - val_accuracy: 0.6567\n",
            "Epoch 167/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3663 - accuracy: 0.8400 - val_loss: 1.5661 - val_accuracy: 0.6367\n",
            "Epoch 168/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3646 - accuracy: 0.8371 - val_loss: 1.5938 - val_accuracy: 0.6167\n",
            "Epoch 169/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3623 - accuracy: 0.8286 - val_loss: 1.5932 - val_accuracy: 0.6300\n",
            "Epoch 170/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3651 - accuracy: 0.8357 - val_loss: 1.5418 - val_accuracy: 0.6667\n",
            "Epoch 171/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3596 - accuracy: 0.8371 - val_loss: 1.6228 - val_accuracy: 0.6300\n",
            "Epoch 172/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3582 - accuracy: 0.8400 - val_loss: 1.5277 - val_accuracy: 0.6533\n",
            "Epoch 173/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.3625 - accuracy: 0.8386 - val_loss: 1.5767 - val_accuracy: 0.6667\n",
            "Epoch 174/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.3462 - accuracy: 0.8543 - val_loss: 1.5681 - val_accuracy: 0.6600\n",
            "Epoch 175/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3541 - accuracy: 0.8357 - val_loss: 1.5589 - val_accuracy: 0.6600\n",
            "Epoch 176/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3534 - accuracy: 0.8400 - val_loss: 1.6207 - val_accuracy: 0.6400\n",
            "Epoch 177/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3533 - accuracy: 0.8457 - val_loss: 1.6390 - val_accuracy: 0.6533\n",
            "Epoch 178/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3417 - accuracy: 0.8500 - val_loss: 1.6828 - val_accuracy: 0.6400\n",
            "Epoch 179/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3456 - accuracy: 0.8514 - val_loss: 1.6041 - val_accuracy: 0.6533\n",
            "Epoch 180/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3404 - accuracy: 0.8529 - val_loss: 1.6486 - val_accuracy: 0.6333\n",
            "Epoch 181/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3467 - accuracy: 0.8429 - val_loss: 1.6961 - val_accuracy: 0.6367\n",
            "Epoch 182/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.3549 - accuracy: 0.8429 - val_loss: 1.6643 - val_accuracy: 0.6467\n",
            "Epoch 183/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.3356 - accuracy: 0.8486 - val_loss: 1.6543 - val_accuracy: 0.6867\n",
            "Epoch 184/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3406 - accuracy: 0.8386 - val_loss: 1.6489 - val_accuracy: 0.6567\n",
            "Epoch 185/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3356 - accuracy: 0.8614 - val_loss: 1.6992 - val_accuracy: 0.6333\n",
            "Epoch 186/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3300 - accuracy: 0.8500 - val_loss: 1.7131 - val_accuracy: 0.6767\n",
            "Epoch 187/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3298 - accuracy: 0.8500 - val_loss: 1.7673 - val_accuracy: 0.6333\n",
            "Epoch 188/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3377 - accuracy: 0.8557 - val_loss: 1.7975 - val_accuracy: 0.6600\n",
            "Epoch 189/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3295 - accuracy: 0.8457 - val_loss: 1.7299 - val_accuracy: 0.6567\n",
            "Epoch 190/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.3362 - accuracy: 0.8429 - val_loss: 1.7576 - val_accuracy: 0.6600\n",
            "Epoch 191/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.3197 - accuracy: 0.8657 - val_loss: 1.7318 - val_accuracy: 0.6600\n",
            "Epoch 192/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3439 - accuracy: 0.8371 - val_loss: 1.7305 - val_accuracy: 0.6433\n",
            "Epoch 193/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3222 - accuracy: 0.8643 - val_loss: 1.7234 - val_accuracy: 0.6400\n",
            "Epoch 194/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3104 - accuracy: 0.8643 - val_loss: 1.8162 - val_accuracy: 0.6600\n",
            "Epoch 195/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3351 - accuracy: 0.8543 - val_loss: 1.8200 - val_accuracy: 0.6533\n",
            "Epoch 196/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3290 - accuracy: 0.8629 - val_loss: 1.7385 - val_accuracy: 0.6667\n",
            "Epoch 197/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3161 - accuracy: 0.8629 - val_loss: 1.8401 - val_accuracy: 0.6467\n",
            "Epoch 198/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.3172 - accuracy: 0.8629 - val_loss: 1.8142 - val_accuracy: 0.6533\n",
            "Epoch 199/500\n",
            "350/350 [==============================] - 3s 8ms/step - loss: 0.3105 - accuracy: 0.8557 - val_loss: 1.8752 - val_accuracy: 0.6633\n",
            "Epoch 200/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3260 - accuracy: 0.8500 - val_loss: 1.9070 - val_accuracy: 0.6367\n",
            "Epoch 201/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3148 - accuracy: 0.8557 - val_loss: 1.8861 - val_accuracy: 0.6700\n",
            "Epoch 202/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3114 - accuracy: 0.8700 - val_loss: 1.9263 - val_accuracy: 0.6233\n",
            "Epoch 203/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3037 - accuracy: 0.8771 - val_loss: 1.8224 - val_accuracy: 0.6600\n",
            "Epoch 204/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3057 - accuracy: 0.8814 - val_loss: 2.0048 - val_accuracy: 0.6467\n",
            "Epoch 205/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3051 - accuracy: 0.8771 - val_loss: 1.8863 - val_accuracy: 0.6633\n",
            "Epoch 206/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.3055 - accuracy: 0.8571 - val_loss: 1.8715 - val_accuracy: 0.6533\n",
            "Epoch 207/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.3190 - accuracy: 0.8571 - val_loss: 1.8752 - val_accuracy: 0.6467\n",
            "Epoch 208/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3157 - accuracy: 0.8571 - val_loss: 1.9587 - val_accuracy: 0.6567\n",
            "Epoch 209/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3029 - accuracy: 0.8657 - val_loss: 1.8304 - val_accuracy: 0.6467\n",
            "Epoch 210/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3076 - accuracy: 0.8700 - val_loss: 1.8547 - val_accuracy: 0.6767\n",
            "Epoch 211/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3012 - accuracy: 0.8643 - val_loss: 1.9220 - val_accuracy: 0.6433\n",
            "Epoch 212/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3053 - accuracy: 0.8557 - val_loss: 1.9303 - val_accuracy: 0.6433\n",
            "Epoch 213/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2964 - accuracy: 0.8600 - val_loss: 1.9324 - val_accuracy: 0.6633\n",
            "Epoch 214/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.2938 - accuracy: 0.8700 - val_loss: 1.9446 - val_accuracy: 0.6333\n",
            "Epoch 215/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.2976 - accuracy: 0.8729 - val_loss: 2.0448 - val_accuracy: 0.6500\n",
            "Epoch 216/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2962 - accuracy: 0.8771 - val_loss: 1.9260 - val_accuracy: 0.6367\n",
            "Epoch 217/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2926 - accuracy: 0.8700 - val_loss: 1.9873 - val_accuracy: 0.6467\n",
            "Epoch 218/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2982 - accuracy: 0.8686 - val_loss: 2.0105 - val_accuracy: 0.6433\n",
            "Epoch 219/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2972 - accuracy: 0.8671 - val_loss: 2.0643 - val_accuracy: 0.6467\n",
            "Epoch 220/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2840 - accuracy: 0.8729 - val_loss: 2.0308 - val_accuracy: 0.6533\n",
            "Epoch 221/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2876 - accuracy: 0.8700 - val_loss: 1.9833 - val_accuracy: 0.6533\n",
            "Epoch 222/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.2825 - accuracy: 0.8757 - val_loss: 2.0633 - val_accuracy: 0.6433\n",
            "Epoch 223/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.2951 - accuracy: 0.8586 - val_loss: 2.0216 - val_accuracy: 0.6533\n",
            "Epoch 224/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2877 - accuracy: 0.8786 - val_loss: 2.0892 - val_accuracy: 0.6333\n",
            "Epoch 225/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2746 - accuracy: 0.8771 - val_loss: 2.0783 - val_accuracy: 0.6467\n",
            "Epoch 226/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2827 - accuracy: 0.8771 - val_loss: 2.0640 - val_accuracy: 0.6467\n",
            "Epoch 227/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2769 - accuracy: 0.8857 - val_loss: 2.1433 - val_accuracy: 0.6500\n",
            "Epoch 228/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2820 - accuracy: 0.8843 - val_loss: 2.1074 - val_accuracy: 0.6500\n",
            "Epoch 229/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2686 - accuracy: 0.8757 - val_loss: 2.1496 - val_accuracy: 0.6433\n",
            "Epoch 230/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2781 - accuracy: 0.8786 - val_loss: 2.1652 - val_accuracy: 0.6367\n",
            "Epoch 231/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.2793 - accuracy: 0.8757 - val_loss: 2.2021 - val_accuracy: 0.6267\n",
            "Epoch 232/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.2818 - accuracy: 0.8686 - val_loss: 2.1335 - val_accuracy: 0.6300\n",
            "Epoch 233/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2649 - accuracy: 0.8829 - val_loss: 2.2165 - val_accuracy: 0.6633\n",
            "Epoch 234/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2790 - accuracy: 0.8714 - val_loss: 2.1369 - val_accuracy: 0.6667\n",
            "Epoch 235/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2595 - accuracy: 0.8814 - val_loss: 2.0550 - val_accuracy: 0.6633\n",
            "Epoch 236/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2669 - accuracy: 0.8757 - val_loss: 2.2271 - val_accuracy: 0.6567\n",
            "Epoch 237/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2661 - accuracy: 0.8757 - val_loss: 2.2113 - val_accuracy: 0.6400\n",
            "Epoch 238/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2686 - accuracy: 0.8814 - val_loss: 2.2480 - val_accuracy: 0.6400\n",
            "Epoch 239/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.2780 - accuracy: 0.8786 - val_loss: 2.1571 - val_accuracy: 0.6367\n",
            "Epoch 240/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.2582 - accuracy: 0.8900 - val_loss: 2.1484 - val_accuracy: 0.6533\n",
            "Epoch 241/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2779 - accuracy: 0.8729 - val_loss: 2.2525 - val_accuracy: 0.6500\n",
            "Epoch 242/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2492 - accuracy: 0.8857 - val_loss: 2.3304 - val_accuracy: 0.6300\n",
            "Epoch 243/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2631 - accuracy: 0.8886 - val_loss: 2.3391 - val_accuracy: 0.6533\n",
            "Epoch 244/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2690 - accuracy: 0.8771 - val_loss: 2.2780 - val_accuracy: 0.6467\n",
            "Epoch 245/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2536 - accuracy: 0.8929 - val_loss: 2.2966 - val_accuracy: 0.6567\n",
            "Epoch 246/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2640 - accuracy: 0.8871 - val_loss: 2.2951 - val_accuracy: 0.6633\n",
            "Epoch 247/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2570 - accuracy: 0.8843 - val_loss: 2.2579 - val_accuracy: 0.6633\n",
            "Epoch 248/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.2442 - accuracy: 0.8929 - val_loss: 2.3378 - val_accuracy: 0.6300\n",
            "Epoch 249/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.2518 - accuracy: 0.8800 - val_loss: 2.3347 - val_accuracy: 0.6500\n",
            "Epoch 250/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2560 - accuracy: 0.8886 - val_loss: 2.3226 - val_accuracy: 0.6500\n",
            "Epoch 251/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2596 - accuracy: 0.8743 - val_loss: 2.3087 - val_accuracy: 0.6533\n",
            "Epoch 252/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2447 - accuracy: 0.8900 - val_loss: 2.3350 - val_accuracy: 0.6467\n",
            "Epoch 253/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2514 - accuracy: 0.8829 - val_loss: 2.3978 - val_accuracy: 0.6367\n",
            "Epoch 254/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2372 - accuracy: 0.9029 - val_loss: 2.4674 - val_accuracy: 0.6367\n",
            "Epoch 255/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2549 - accuracy: 0.8886 - val_loss: 2.3946 - val_accuracy: 0.6300\n",
            "Epoch 256/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.2570 - accuracy: 0.8886 - val_loss: 2.3794 - val_accuracy: 0.6467\n",
            "Epoch 257/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.2403 - accuracy: 0.8829 - val_loss: 2.4013 - val_accuracy: 0.6500\n",
            "Epoch 258/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2438 - accuracy: 0.8914 - val_loss: 2.4718 - val_accuracy: 0.6200\n",
            "Epoch 259/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2645 - accuracy: 0.8871 - val_loss: 2.3990 - val_accuracy: 0.6267\n",
            "Epoch 260/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2477 - accuracy: 0.8871 - val_loss: 2.5192 - val_accuracy: 0.6700\n",
            "Epoch 261/500\n",
            "350/350 [==============================] - 2s 4ms/step - loss: 0.2387 - accuracy: 0.8857 - val_loss: 2.4572 - val_accuracy: 0.6333\n",
            "Epoch 262/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2433 - accuracy: 0.9000 - val_loss: 2.4541 - val_accuracy: 0.6367\n",
            "Epoch 263/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2439 - accuracy: 0.8986 - val_loss: 2.4659 - val_accuracy: 0.6500\n",
            "Epoch 264/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.2419 - accuracy: 0.8871 - val_loss: 2.4828 - val_accuracy: 0.6533\n",
            "Epoch 265/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.2418 - accuracy: 0.8986 - val_loss: 2.4935 - val_accuracy: 0.6600\n",
            "Epoch 266/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2449 - accuracy: 0.8957 - val_loss: 2.3804 - val_accuracy: 0.6400\n",
            "Epoch 267/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2383 - accuracy: 0.8900 - val_loss: 2.5553 - val_accuracy: 0.6333\n",
            "Epoch 268/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2326 - accuracy: 0.8986 - val_loss: 2.5559 - val_accuracy: 0.6367\n",
            "Epoch 269/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2316 - accuracy: 0.8986 - val_loss: 2.5339 - val_accuracy: 0.6300\n",
            "Epoch 270/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2308 - accuracy: 0.8914 - val_loss: 2.5379 - val_accuracy: 0.6567\n",
            "Epoch 271/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2309 - accuracy: 0.9000 - val_loss: 2.5881 - val_accuracy: 0.6300\n",
            "Epoch 272/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2378 - accuracy: 0.8943 - val_loss: 2.5351 - val_accuracy: 0.6467\n",
            "Epoch 273/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.2305 - accuracy: 0.9000 - val_loss: 2.5261 - val_accuracy: 0.6333\n",
            "Epoch 274/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.2333 - accuracy: 0.8900 - val_loss: 2.5309 - val_accuracy: 0.6600\n",
            "Epoch 275/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2406 - accuracy: 0.8957 - val_loss: 2.5981 - val_accuracy: 0.6367\n",
            "Epoch 276/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2140 - accuracy: 0.9100 - val_loss: 2.6031 - val_accuracy: 0.6433\n",
            "Epoch 277/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2234 - accuracy: 0.8929 - val_loss: 2.5838 - val_accuracy: 0.6467\n",
            "Epoch 278/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2295 - accuracy: 0.8871 - val_loss: 2.6583 - val_accuracy: 0.6533\n",
            "Epoch 279/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2290 - accuracy: 0.9000 - val_loss: 2.6227 - val_accuracy: 0.6567\n",
            "Epoch 280/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2166 - accuracy: 0.9071 - val_loss: 2.7011 - val_accuracy: 0.6600\n",
            "Epoch 281/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.2102 - accuracy: 0.9229 - val_loss: 2.6312 - val_accuracy: 0.6567\n",
            "Epoch 282/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.2257 - accuracy: 0.8957 - val_loss: 2.5691 - val_accuracy: 0.6500\n",
            "Epoch 283/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2131 - accuracy: 0.9057 - val_loss: 2.6627 - val_accuracy: 0.6333\n",
            "Epoch 284/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2288 - accuracy: 0.8886 - val_loss: 2.6382 - val_accuracy: 0.6600\n",
            "Epoch 285/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2130 - accuracy: 0.9100 - val_loss: 2.7405 - val_accuracy: 0.6400\n",
            "Epoch 286/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2168 - accuracy: 0.9029 - val_loss: 2.7350 - val_accuracy: 0.6567\n",
            "Epoch 287/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2077 - accuracy: 0.9057 - val_loss: 2.7152 - val_accuracy: 0.6467\n",
            "Epoch 288/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2187 - accuracy: 0.9000 - val_loss: 2.6259 - val_accuracy: 0.6667\n",
            "Epoch 289/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.2071 - accuracy: 0.9071 - val_loss: 2.6137 - val_accuracy: 0.6400\n",
            "Epoch 290/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.2111 - accuracy: 0.9029 - val_loss: 2.7580 - val_accuracy: 0.6767\n",
            "Epoch 291/500\n",
            "350/350 [==============================] - 2s 4ms/step - loss: 0.2193 - accuracy: 0.9114 - val_loss: 2.7479 - val_accuracy: 0.6300\n",
            "Epoch 292/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2090 - accuracy: 0.9129 - val_loss: 2.7668 - val_accuracy: 0.6433\n",
            "Epoch 293/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2136 - accuracy: 0.9029 - val_loss: 2.7733 - val_accuracy: 0.6567\n",
            "Epoch 294/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1911 - accuracy: 0.9143 - val_loss: 2.7759 - val_accuracy: 0.6567\n",
            "Epoch 295/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1973 - accuracy: 0.9100 - val_loss: 2.8039 - val_accuracy: 0.6400\n",
            "Epoch 296/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2130 - accuracy: 0.9086 - val_loss: 2.8928 - val_accuracy: 0.6433\n",
            "Epoch 297/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2085 - accuracy: 0.9157 - val_loss: 2.7605 - val_accuracy: 0.6433\n",
            "Epoch 298/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.1977 - accuracy: 0.9086 - val_loss: 2.8425 - val_accuracy: 0.6467\n",
            "Epoch 299/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.2240 - accuracy: 0.9014 - val_loss: 2.8206 - val_accuracy: 0.6467\n",
            "Epoch 300/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2088 - accuracy: 0.8986 - val_loss: 2.8581 - val_accuracy: 0.6233\n",
            "Epoch 301/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1925 - accuracy: 0.9214 - val_loss: 2.9045 - val_accuracy: 0.6333\n",
            "Epoch 302/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2108 - accuracy: 0.9029 - val_loss: 2.7897 - val_accuracy: 0.6433\n",
            "Epoch 303/500\n",
            "350/350 [==============================] - 2s 4ms/step - loss: 0.1948 - accuracy: 0.9057 - val_loss: 2.8477 - val_accuracy: 0.6367\n",
            "Epoch 304/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1959 - accuracy: 0.9214 - val_loss: 2.8651 - val_accuracy: 0.6300\n",
            "Epoch 305/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1992 - accuracy: 0.9200 - val_loss: 2.8817 - val_accuracy: 0.6533\n",
            "Epoch 306/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.1994 - accuracy: 0.9114 - val_loss: 2.9476 - val_accuracy: 0.6500\n",
            "Epoch 307/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.1955 - accuracy: 0.9186 - val_loss: 2.9942 - val_accuracy: 0.6367\n",
            "Epoch 308/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2084 - accuracy: 0.9086 - val_loss: 2.9919 - val_accuracy: 0.6567\n",
            "Epoch 309/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1819 - accuracy: 0.9229 - val_loss: 3.0010 - val_accuracy: 0.6533\n",
            "Epoch 310/500\n",
            "350/350 [==============================] - 2s 4ms/step - loss: 0.1976 - accuracy: 0.9157 - val_loss: 2.9618 - val_accuracy: 0.6267\n",
            "Epoch 311/500\n",
            "350/350 [==============================] - 2s 4ms/step - loss: 0.1952 - accuracy: 0.9200 - val_loss: 2.9671 - val_accuracy: 0.6333\n",
            "Epoch 312/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.1948 - accuracy: 0.9229 - val_loss: 3.0198 - val_accuracy: 0.6333\n",
            "Epoch 313/500\n",
            "350/350 [==============================] - 2s 4ms/step - loss: 0.1825 - accuracy: 0.9229 - val_loss: 2.9557 - val_accuracy: 0.6467\n",
            "Epoch 314/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.1895 - accuracy: 0.9157 - val_loss: 3.0061 - val_accuracy: 0.6333\n",
            "Epoch 315/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.1949 - accuracy: 0.9071 - val_loss: 2.9666 - val_accuracy: 0.6700\n",
            "Epoch 316/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1818 - accuracy: 0.9157 - val_loss: 3.0114 - val_accuracy: 0.6400\n",
            "Epoch 317/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1766 - accuracy: 0.9214 - val_loss: 3.0977 - val_accuracy: 0.6467\n",
            "Epoch 318/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1906 - accuracy: 0.9200 - val_loss: 3.1034 - val_accuracy: 0.6433\n",
            "Epoch 319/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1921 - accuracy: 0.9114 - val_loss: 3.0984 - val_accuracy: 0.6500\n",
            "Epoch 320/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1766 - accuracy: 0.9286 - val_loss: 3.1409 - val_accuracy: 0.6533\n",
            "Epoch 321/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1793 - accuracy: 0.9257 - val_loss: 3.1414 - val_accuracy: 0.6667\n",
            "Epoch 322/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.1741 - accuracy: 0.9243 - val_loss: 3.1995 - val_accuracy: 0.6367\n",
            "Epoch 323/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.1850 - accuracy: 0.9200 - val_loss: 3.0802 - val_accuracy: 0.6567\n",
            "Epoch 324/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1833 - accuracy: 0.9300 - val_loss: 3.1194 - val_accuracy: 0.6267\n",
            "Epoch 325/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1835 - accuracy: 0.9157 - val_loss: 3.1156 - val_accuracy: 0.6400\n",
            "Epoch 326/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1774 - accuracy: 0.9229 - val_loss: 3.0550 - val_accuracy: 0.6600\n",
            "Epoch 327/500\n",
            "350/350 [==============================] - 2s 4ms/step - loss: 0.1911 - accuracy: 0.9186 - val_loss: 3.0895 - val_accuracy: 0.6400\n",
            "Epoch 328/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1821 - accuracy: 0.9100 - val_loss: 3.1044 - val_accuracy: 0.6567\n",
            "Epoch 329/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1679 - accuracy: 0.9329 - val_loss: 3.1504 - val_accuracy: 0.6533\n",
            "Epoch 330/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.1797 - accuracy: 0.9071 - val_loss: 3.1536 - val_accuracy: 0.6567\n",
            "Epoch 331/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.1925 - accuracy: 0.9100 - val_loss: 3.1270 - val_accuracy: 0.6567\n",
            "Epoch 332/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.1844 - accuracy: 0.9257 - val_loss: 3.1224 - val_accuracy: 0.6333\n",
            "Epoch 333/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1799 - accuracy: 0.9200 - val_loss: 3.1675 - val_accuracy: 0.6533\n",
            "Epoch 334/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1732 - accuracy: 0.9329 - val_loss: 3.2401 - val_accuracy: 0.6567\n",
            "Epoch 335/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1739 - accuracy: 0.9271 - val_loss: 3.2369 - val_accuracy: 0.6300\n",
            "Epoch 336/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1885 - accuracy: 0.9114 - val_loss: 3.1416 - val_accuracy: 0.6433\n",
            "Epoch 337/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1657 - accuracy: 0.9271 - val_loss: 3.1568 - val_accuracy: 0.6367\n",
            "Epoch 338/500\n",
            "350/350 [==============================] - 2s 4ms/step - loss: 0.1712 - accuracy: 0.9314 - val_loss: 3.2666 - val_accuracy: 0.6333\n",
            "Epoch 339/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.1802 - accuracy: 0.9214 - val_loss: 3.3085 - val_accuracy: 0.6433\n",
            "Epoch 340/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.1865 - accuracy: 0.9314 - val_loss: 3.3414 - val_accuracy: 0.6500\n",
            "Epoch 341/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1706 - accuracy: 0.9286 - val_loss: 3.2194 - val_accuracy: 0.6733\n",
            "Epoch 342/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1767 - accuracy: 0.9257 - val_loss: 3.2252 - val_accuracy: 0.6567\n",
            "Epoch 343/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1659 - accuracy: 0.9271 - val_loss: 3.2214 - val_accuracy: 0.6167\n",
            "Epoch 344/500\n",
            "350/350 [==============================] - 2s 4ms/step - loss: 0.1685 - accuracy: 0.9271 - val_loss: 3.2546 - val_accuracy: 0.6800\n",
            "Epoch 345/500\n",
            "350/350 [==============================] - 2s 4ms/step - loss: 0.1674 - accuracy: 0.9300 - val_loss: 3.2646 - val_accuracy: 0.6633\n",
            "Epoch 346/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1609 - accuracy: 0.9300 - val_loss: 3.2491 - val_accuracy: 0.6633\n",
            "Epoch 347/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.1705 - accuracy: 0.9229 - val_loss: 3.2961 - val_accuracy: 0.6467\n",
            "Epoch 348/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.1698 - accuracy: 0.9329 - val_loss: 3.3199 - val_accuracy: 0.6367\n",
            "Epoch 349/500\n",
            "350/350 [==============================] - 2s 4ms/step - loss: 0.1626 - accuracy: 0.9286 - val_loss: 3.4029 - val_accuracy: 0.6300\n",
            "Epoch 350/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1629 - accuracy: 0.9286 - val_loss: 3.3163 - val_accuracy: 0.6333\n",
            "Epoch 351/500\n",
            "350/350 [==============================] - 2s 4ms/step - loss: 0.1543 - accuracy: 0.9243 - val_loss: 3.3145 - val_accuracy: 0.6400\n",
            "Epoch 352/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1679 - accuracy: 0.9286 - val_loss: 3.2715 - val_accuracy: 0.6700\n",
            "Epoch 353/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1689 - accuracy: 0.9314 - val_loss: 3.3380 - val_accuracy: 0.6500\n",
            "Epoch 354/500\n",
            "350/350 [==============================] - 2s 4ms/step - loss: 0.1489 - accuracy: 0.9314 - val_loss: 3.4479 - val_accuracy: 0.6567\n",
            "Epoch 355/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.1618 - accuracy: 0.9300 - val_loss: 3.3688 - val_accuracy: 0.6667\n",
            "Epoch 356/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.1519 - accuracy: 0.9300 - val_loss: 3.3648 - val_accuracy: 0.6600\n",
            "Epoch 357/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1626 - accuracy: 0.9314 - val_loss: 3.5136 - val_accuracy: 0.6400\n",
            "Epoch 358/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1708 - accuracy: 0.9314 - val_loss: 3.3995 - val_accuracy: 0.6533\n",
            "Epoch 359/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1666 - accuracy: 0.9286 - val_loss: 3.3620 - val_accuracy: 0.6333\n",
            "Epoch 360/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1701 - accuracy: 0.9314 - val_loss: 3.4045 - val_accuracy: 0.6600\n",
            "Epoch 361/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1532 - accuracy: 0.9343 - val_loss: 3.3791 - val_accuracy: 0.6733\n",
            "Epoch 362/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1571 - accuracy: 0.9271 - val_loss: 3.4201 - val_accuracy: 0.6467\n",
            "Epoch 363/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.1405 - accuracy: 0.9471 - val_loss: 3.3867 - val_accuracy: 0.6600\n",
            "Epoch 364/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.1762 - accuracy: 0.9243 - val_loss: 3.4452 - val_accuracy: 0.6500\n",
            "Epoch 365/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.1716 - accuracy: 0.9300 - val_loss: 3.4287 - val_accuracy: 0.6567\n",
            "Epoch 366/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1425 - accuracy: 0.9386 - val_loss: 3.4968 - val_accuracy: 0.6467\n",
            "Epoch 367/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1830 - accuracy: 0.9257 - val_loss: 3.6652 - val_accuracy: 0.6300\n",
            "Epoch 368/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1475 - accuracy: 0.9371 - val_loss: 3.5565 - val_accuracy: 0.6567\n",
            "Epoch 369/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1405 - accuracy: 0.9329 - val_loss: 3.4524 - val_accuracy: 0.6467\n",
            "Epoch 370/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1633 - accuracy: 0.9271 - val_loss: 3.5001 - val_accuracy: 0.6567\n",
            "Epoch 371/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1476 - accuracy: 0.9286 - val_loss: 3.6027 - val_accuracy: 0.6400\n",
            "Epoch 372/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.1394 - accuracy: 0.9443 - val_loss: 3.5957 - val_accuracy: 0.6767\n",
            "Epoch 373/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.1454 - accuracy: 0.9429 - val_loss: 3.5589 - val_accuracy: 0.6633\n",
            "Epoch 374/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1607 - accuracy: 0.9300 - val_loss: 3.6556 - val_accuracy: 0.6600\n",
            "Epoch 375/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1425 - accuracy: 0.9486 - val_loss: 3.6320 - val_accuracy: 0.6367\n",
            "Epoch 376/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1449 - accuracy: 0.9414 - val_loss: 3.7052 - val_accuracy: 0.6300\n",
            "Epoch 377/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1483 - accuracy: 0.9429 - val_loss: 3.7352 - val_accuracy: 0.6600\n",
            "Epoch 378/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1414 - accuracy: 0.9443 - val_loss: 3.7617 - val_accuracy: 0.6333\n",
            "Epoch 379/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1481 - accuracy: 0.9429 - val_loss: 3.7427 - val_accuracy: 0.6400\n",
            "Epoch 380/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.1457 - accuracy: 0.9343 - val_loss: 3.6590 - val_accuracy: 0.6467\n",
            "Epoch 381/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.1358 - accuracy: 0.9414 - val_loss: 3.7946 - val_accuracy: 0.6167\n",
            "Epoch 382/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1452 - accuracy: 0.9329 - val_loss: 3.5481 - val_accuracy: 0.6300\n",
            "Epoch 383/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1589 - accuracy: 0.9314 - val_loss: 3.6712 - val_accuracy: 0.6400\n",
            "Epoch 384/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1307 - accuracy: 0.9571 - val_loss: 3.7457 - val_accuracy: 0.6400\n",
            "Epoch 385/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1806 - accuracy: 0.9214 - val_loss: 3.7237 - val_accuracy: 0.6433\n",
            "Epoch 386/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1411 - accuracy: 0.9386 - val_loss: 3.7703 - val_accuracy: 0.6633\n",
            "Epoch 387/500\n",
            "350/350 [==============================] - 2s 4ms/step - loss: 0.1444 - accuracy: 0.9400 - val_loss: 3.7689 - val_accuracy: 0.6267\n",
            "Epoch 388/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.1541 - accuracy: 0.9386 - val_loss: 3.7241 - val_accuracy: 0.6667\n",
            "Epoch 389/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.1346 - accuracy: 0.9443 - val_loss: 3.8730 - val_accuracy: 0.6467\n",
            "Epoch 390/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1350 - accuracy: 0.9486 - val_loss: 3.6709 - val_accuracy: 0.6600\n",
            "Epoch 391/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1399 - accuracy: 0.9471 - val_loss: 3.8059 - val_accuracy: 0.6667\n",
            "Epoch 392/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1498 - accuracy: 0.9314 - val_loss: 3.7529 - val_accuracy: 0.6567\n",
            "Epoch 393/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1351 - accuracy: 0.9457 - val_loss: 3.6788 - val_accuracy: 0.6467\n",
            "Epoch 394/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1260 - accuracy: 0.9529 - val_loss: 3.7055 - val_accuracy: 0.6600\n",
            "Epoch 395/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1440 - accuracy: 0.9429 - val_loss: 3.8245 - val_accuracy: 0.6633\n",
            "Epoch 396/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1406 - accuracy: 0.9414 - val_loss: 3.8725 - val_accuracy: 0.6167\n",
            "Epoch 397/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.1555 - accuracy: 0.9200 - val_loss: 3.8162 - val_accuracy: 0.6467\n",
            "Epoch 398/500\n",
            "350/350 [==============================] - 2s 4ms/step - loss: 0.1419 - accuracy: 0.9429 - val_loss: 3.7914 - val_accuracy: 0.6367\n",
            "Epoch 399/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1281 - accuracy: 0.9514 - val_loss: 3.6370 - val_accuracy: 0.6367\n",
            "Epoch 400/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1360 - accuracy: 0.9414 - val_loss: 3.8353 - val_accuracy: 0.6333\n",
            "Epoch 401/500\n",
            "350/350 [==============================] - 2s 4ms/step - loss: 0.1313 - accuracy: 0.9443 - val_loss: 3.8457 - val_accuracy: 0.6533\n",
            "Epoch 402/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1449 - accuracy: 0.9443 - val_loss: 3.8904 - val_accuracy: 0.6567\n",
            "Epoch 403/500\n",
            "350/350 [==============================] - 2s 4ms/step - loss: 0.1366 - accuracy: 0.9429 - val_loss: 3.8561 - val_accuracy: 0.6533\n",
            "Epoch 404/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1378 - accuracy: 0.9443 - val_loss: 3.8642 - val_accuracy: 0.6567\n",
            "Epoch 405/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.1369 - accuracy: 0.9357 - val_loss: 3.8352 - val_accuracy: 0.6567\n",
            "Epoch 406/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.1427 - accuracy: 0.9471 - val_loss: 3.9476 - val_accuracy: 0.6600\n",
            "Epoch 407/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1645 - accuracy: 0.9271 - val_loss: 3.9190 - val_accuracy: 0.6367\n",
            "Epoch 408/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1164 - accuracy: 0.9543 - val_loss: 3.9270 - val_accuracy: 0.6600\n",
            "Epoch 409/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1453 - accuracy: 0.9400 - val_loss: 3.9661 - val_accuracy: 0.6733\n",
            "Epoch 410/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1301 - accuracy: 0.9400 - val_loss: 4.0023 - val_accuracy: 0.6600\n",
            "Epoch 411/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1385 - accuracy: 0.9443 - val_loss: 3.9719 - val_accuracy: 0.6500\n",
            "Epoch 412/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1314 - accuracy: 0.9443 - val_loss: 3.9830 - val_accuracy: 0.6433\n",
            "Epoch 413/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.1305 - accuracy: 0.9443 - val_loss: 4.0608 - val_accuracy: 0.6367\n",
            "Epoch 414/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.1334 - accuracy: 0.9457 - val_loss: 4.0058 - val_accuracy: 0.6433\n",
            "Epoch 415/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1255 - accuracy: 0.9457 - val_loss: 4.0359 - val_accuracy: 0.6500\n",
            "Epoch 416/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1125 - accuracy: 0.9600 - val_loss: 4.1403 - val_accuracy: 0.6400\n",
            "Epoch 417/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1477 - accuracy: 0.9257 - val_loss: 4.0183 - val_accuracy: 0.6567\n",
            "Epoch 418/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1417 - accuracy: 0.9357 - val_loss: 4.0456 - val_accuracy: 0.6500\n",
            "Epoch 419/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1609 - accuracy: 0.9271 - val_loss: 3.9772 - val_accuracy: 0.6500\n",
            "Epoch 420/500\n",
            "350/350 [==============================] - 2s 4ms/step - loss: 0.1278 - accuracy: 0.9529 - val_loss: 4.2066 - val_accuracy: 0.6467\n",
            "Epoch 421/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.1183 - accuracy: 0.9586 - val_loss: 4.0507 - val_accuracy: 0.6633\n",
            "Epoch 422/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.1357 - accuracy: 0.9471 - val_loss: 3.9816 - val_accuracy: 0.6567\n",
            "Epoch 423/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1213 - accuracy: 0.9529 - val_loss: 3.9856 - val_accuracy: 0.6567\n",
            "Epoch 424/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1392 - accuracy: 0.9329 - val_loss: 3.9807 - val_accuracy: 0.6433\n",
            "Epoch 425/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1083 - accuracy: 0.9586 - val_loss: 4.0576 - val_accuracy: 0.6400\n",
            "Epoch 426/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1230 - accuracy: 0.9486 - val_loss: 4.1656 - val_accuracy: 0.6533\n",
            "Epoch 427/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1245 - accuracy: 0.9543 - val_loss: 4.1726 - val_accuracy: 0.6433\n",
            "Epoch 428/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1217 - accuracy: 0.9514 - val_loss: 4.2303 - val_accuracy: 0.6433\n",
            "Epoch 429/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.1144 - accuracy: 0.9543 - val_loss: 4.1705 - val_accuracy: 0.6567\n",
            "Epoch 430/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.1227 - accuracy: 0.9486 - val_loss: 4.3197 - val_accuracy: 0.6167\n",
            "Epoch 431/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1247 - accuracy: 0.9557 - val_loss: 4.1268 - val_accuracy: 0.6667\n",
            "Epoch 432/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1036 - accuracy: 0.9586 - val_loss: 4.2162 - val_accuracy: 0.6567\n",
            "Epoch 433/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1400 - accuracy: 0.9471 - val_loss: 4.3145 - val_accuracy: 0.6633\n",
            "Epoch 434/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1084 - accuracy: 0.9571 - val_loss: 4.2859 - val_accuracy: 0.6400\n",
            "Epoch 435/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1332 - accuracy: 0.9414 - val_loss: 4.1244 - val_accuracy: 0.6500\n",
            "Epoch 436/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1025 - accuracy: 0.9643 - val_loss: 4.1536 - val_accuracy: 0.6667\n",
            "Epoch 437/500\n",
            "350/350 [==============================] - 2s 4ms/step - loss: 0.1249 - accuracy: 0.9471 - val_loss: 4.2545 - val_accuracy: 0.6433\n",
            "Epoch 438/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.1247 - accuracy: 0.9471 - val_loss: 4.4258 - val_accuracy: 0.6467\n",
            "Epoch 439/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.1241 - accuracy: 0.9514 - val_loss: 4.2575 - val_accuracy: 0.6533\n",
            "Epoch 440/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1275 - accuracy: 0.9429 - val_loss: 4.3250 - val_accuracy: 0.6600\n",
            "Epoch 441/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1265 - accuracy: 0.9557 - val_loss: 4.1426 - val_accuracy: 0.6467\n",
            "Epoch 442/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1043 - accuracy: 0.9571 - val_loss: 4.3911 - val_accuracy: 0.6600\n",
            "Epoch 443/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1296 - accuracy: 0.9414 - val_loss: 4.2879 - val_accuracy: 0.6433\n",
            "Epoch 444/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1254 - accuracy: 0.9443 - val_loss: 4.3449 - val_accuracy: 0.6500\n",
            "Epoch 445/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1233 - accuracy: 0.9500 - val_loss: 4.2608 - val_accuracy: 0.6700\n",
            "Epoch 446/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.1450 - accuracy: 0.9386 - val_loss: 4.4088 - val_accuracy: 0.6733\n",
            "Epoch 447/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.1072 - accuracy: 0.9657 - val_loss: 4.4203 - val_accuracy: 0.6600\n",
            "Epoch 448/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1237 - accuracy: 0.9529 - val_loss: 4.3108 - val_accuracy: 0.6433\n",
            "Epoch 449/500\n",
            "350/350 [==============================] - 2s 4ms/step - loss: 0.1109 - accuracy: 0.9600 - val_loss: 4.4274 - val_accuracy: 0.6500\n",
            "Epoch 450/500\n",
            "350/350 [==============================] - 2s 4ms/step - loss: 0.1333 - accuracy: 0.9329 - val_loss: 4.1681 - val_accuracy: 0.6500\n",
            "Epoch 451/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1215 - accuracy: 0.9586 - val_loss: 4.3681 - val_accuracy: 0.6333\n",
            "Epoch 452/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1352 - accuracy: 0.9400 - val_loss: 4.3369 - val_accuracy: 0.6533\n",
            "Epoch 453/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1099 - accuracy: 0.9514 - val_loss: 4.4414 - val_accuracy: 0.6133\n",
            "Epoch 454/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.1041 - accuracy: 0.9614 - val_loss: 4.3499 - val_accuracy: 0.6467\n",
            "Epoch 455/500\n",
            "350/350 [==============================] - 2s 7ms/step - loss: 0.1281 - accuracy: 0.9429 - val_loss: 4.4939 - val_accuracy: 0.6500\n",
            "Epoch 456/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1273 - accuracy: 0.9429 - val_loss: 4.3940 - val_accuracy: 0.6233\n",
            "Epoch 457/500\n",
            "350/350 [==============================] - 2s 4ms/step - loss: 0.1095 - accuracy: 0.9557 - val_loss: 4.3124 - val_accuracy: 0.6467\n",
            "Epoch 458/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1260 - accuracy: 0.9500 - val_loss: 4.4067 - val_accuracy: 0.6433\n",
            "Epoch 459/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1087 - accuracy: 0.9500 - val_loss: 4.3798 - val_accuracy: 0.6467\n",
            "Epoch 460/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1047 - accuracy: 0.9529 - val_loss: 4.4108 - val_accuracy: 0.6567\n",
            "Epoch 461/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1235 - accuracy: 0.9529 - val_loss: 4.3777 - val_accuracy: 0.6633\n",
            "Epoch 462/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.1154 - accuracy: 0.9514 - val_loss: 4.3249 - val_accuracy: 0.6467\n",
            "Epoch 463/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.0973 - accuracy: 0.9671 - val_loss: 4.4885 - val_accuracy: 0.6700\n",
            "Epoch 464/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1167 - accuracy: 0.9614 - val_loss: 4.3494 - val_accuracy: 0.6500\n",
            "Epoch 465/500\n",
            "350/350 [==============================] - 2s 4ms/step - loss: 0.1121 - accuracy: 0.9543 - val_loss: 4.3907 - val_accuracy: 0.6400\n",
            "Epoch 466/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1123 - accuracy: 0.9600 - val_loss: 4.3784 - val_accuracy: 0.6533\n",
            "Epoch 467/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1104 - accuracy: 0.9543 - val_loss: 4.6793 - val_accuracy: 0.6367\n",
            "Epoch 468/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.0938 - accuracy: 0.9629 - val_loss: 4.5272 - val_accuracy: 0.6533\n",
            "Epoch 469/500\n",
            "350/350 [==============================] - 2s 4ms/step - loss: 0.1120 - accuracy: 0.9514 - val_loss: 4.4537 - val_accuracy: 0.6500\n",
            "Epoch 470/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.1128 - accuracy: 0.9543 - val_loss: 4.5044 - val_accuracy: 0.6300\n",
            "Epoch 471/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.1136 - accuracy: 0.9500 - val_loss: 4.5085 - val_accuracy: 0.6500\n",
            "Epoch 472/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.1069 - accuracy: 0.9629 - val_loss: 4.4612 - val_accuracy: 0.6433\n",
            "Epoch 473/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1225 - accuracy: 0.9457 - val_loss: 4.5236 - val_accuracy: 0.6400\n",
            "Epoch 474/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1265 - accuracy: 0.9471 - val_loss: 4.6386 - val_accuracy: 0.6567\n",
            "Epoch 475/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1226 - accuracy: 0.9471 - val_loss: 4.3235 - val_accuracy: 0.6500\n",
            "Epoch 476/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1088 - accuracy: 0.9600 - val_loss: 4.6832 - val_accuracy: 0.6300\n",
            "Epoch 477/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.0978 - accuracy: 0.9643 - val_loss: 4.6340 - val_accuracy: 0.6500\n",
            "Epoch 478/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1145 - accuracy: 0.9614 - val_loss: 4.5705 - val_accuracy: 0.6667\n",
            "Epoch 479/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.0956 - accuracy: 0.9657 - val_loss: 4.6876 - val_accuracy: 0.6400\n",
            "Epoch 480/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.1082 - accuracy: 0.9643 - val_loss: 4.7189 - val_accuracy: 0.6500\n",
            "Epoch 481/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1031 - accuracy: 0.9586 - val_loss: 4.6873 - val_accuracy: 0.6233\n",
            "Epoch 482/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1122 - accuracy: 0.9529 - val_loss: 4.6236 - val_accuracy: 0.6400\n",
            "Epoch 483/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1283 - accuracy: 0.9457 - val_loss: 4.5299 - val_accuracy: 0.6533\n",
            "Epoch 484/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.0988 - accuracy: 0.9586 - val_loss: 4.6083 - val_accuracy: 0.6667\n",
            "Epoch 485/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.0963 - accuracy: 0.9586 - val_loss: 4.6180 - val_accuracy: 0.6333\n",
            "Epoch 486/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1017 - accuracy: 0.9543 - val_loss: 4.6991 - val_accuracy: 0.6700\n",
            "Epoch 487/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.1204 - accuracy: 0.9471 - val_loss: 4.6272 - val_accuracy: 0.6200\n",
            "Epoch 488/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.1142 - accuracy: 0.9514 - val_loss: 4.6775 - val_accuracy: 0.6367\n",
            "Epoch 489/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1050 - accuracy: 0.9514 - val_loss: 4.6788 - val_accuracy: 0.6400\n",
            "Epoch 490/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1205 - accuracy: 0.9457 - val_loss: 4.5958 - val_accuracy: 0.6433\n",
            "Epoch 491/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1012 - accuracy: 0.9571 - val_loss: 4.6028 - val_accuracy: 0.6600\n",
            "Epoch 492/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1276 - accuracy: 0.9414 - val_loss: 4.6852 - val_accuracy: 0.6267\n",
            "Epoch 493/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.0864 - accuracy: 0.9714 - val_loss: 4.6868 - val_accuracy: 0.6500\n",
            "Epoch 494/500\n",
            "350/350 [==============================] - 2s 4ms/step - loss: 0.0948 - accuracy: 0.9600 - val_loss: 4.7516 - val_accuracy: 0.6400\n",
            "Epoch 495/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.1287 - accuracy: 0.9471 - val_loss: 4.5441 - val_accuracy: 0.6600\n",
            "Epoch 496/500\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.1126 - accuracy: 0.9514 - val_loss: 4.6220 - val_accuracy: 0.6467\n",
            "Epoch 497/500\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.0871 - accuracy: 0.9657 - val_loss: 4.6834 - val_accuracy: 0.6133\n",
            "Epoch 498/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.0984 - accuracy: 0.9600 - val_loss: 4.6513 - val_accuracy: 0.6500\n",
            "Epoch 499/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1002 - accuracy: 0.9586 - val_loss: 4.7027 - val_accuracy: 0.6533\n",
            "Epoch 500/500\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1151 - accuracy: 0.9600 - val_loss: 4.7392 - val_accuracy: 0.6567\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d2088212aa0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Predict probabilities on the test set\n",
        "y_probs = model.predict(x_test)\n",
        "\n",
        "# Get predicted class labels\n",
        "y_pred = np.argmax(y_probs, axis=1)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Test Accuracy: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHv6-X8Nibmg",
        "outputId": "a429f20a-4a66-409b-ca3f-15fc8ed7b0b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 0s 4ms/step\n",
            "Test Accuracy: 0.89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Display confusion matrix using seaborn\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "fCzJtsOvi8s1",
        "outputId": "e3c2cb34-6534-4aa4-829c-8e025a471e3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}